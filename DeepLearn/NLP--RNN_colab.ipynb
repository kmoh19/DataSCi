{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "NLP--RNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmoh19/DataSCi/blob/master/DeepLearn/NLP--RNN_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV3GgtRx2WFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka4X9iJS2WGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d55d56f5-2317-4dc4-e7b7-6644f3caac9c"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "tf.executing_eagerly()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V94setkF2WHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_file = \"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvryi1ax2WHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=urllib.request.urlopen(path_to_file).readlines()\n",
        "#text = open(path_to_file,'r').read()\n",
        "text=[i.decode('utf-8') for i in text[252:124300]]\n",
        "text=\"\".join(text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVyDOIG92WH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8d0de41e-aecf-4da6-c33a-987b4ce97405"
      },
      "source": [
        "print(text[:100])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose mig\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81oVc5gG2WIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab=sorted(set(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cCfOUDBI2WIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b61e67c3-6069-44ef-ddf7-9924f77145d0"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '>',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " '[',\n",
              " ']',\n",
              " '_',\n",
              " '`',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '|',\n",
              " '}']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwUfRX9I2WI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f012a181-3a21-41d0-9e02-b8800f36a59a"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPzKGvWW2WJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_to_ind ={char:ind for ind,char in enumerate(vocab)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fXGgbVWk2WJ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4344e7c2-dab0-4ed6-bf9d-e990abdc656e"
      },
      "source": [
        "char_to_ind"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " '`': 55,\n",
              " 'a': 56,\n",
              " 'b': 57,\n",
              " 'c': 58,\n",
              " 'd': 59,\n",
              " 'e': 60,\n",
              " 'f': 61,\n",
              " 'g': 62,\n",
              " 'h': 63,\n",
              " 'i': 64,\n",
              " 'j': 65,\n",
              " 'k': 66,\n",
              " 'l': 67,\n",
              " 'm': 68,\n",
              " 'n': 69,\n",
              " 'o': 70,\n",
              " 'p': 71,\n",
              " 'q': 72,\n",
              " 'r': 73,\n",
              " 's': 74,\n",
              " 't': 75,\n",
              " 'u': 76,\n",
              " 'v': 77,\n",
              " 'w': 78,\n",
              " 'x': 79,\n",
              " 'y': 80,\n",
              " 'z': 81,\n",
              " '|': 82,\n",
              " '}': 83}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzq8KHPE2WKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind_to_char=np.array(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oFDCkYY2WLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee7364a9-f035-4e96-8b8e-9e3396756e40"
      },
      "source": [
        "char_to_ind['I'],ind_to_char[33]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34, 'H')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_kjOm3k2WMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_text=np.array([char_to_ind[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2HqGTyh2WMw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef5ac5d3-d8a0-4ce8-816e-8b23574ff023"
      },
      "source": [
        "encoded_text"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1,  1, ..., 80, 10,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RLLvJHg2WNG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4983fdf1-e3eb-45f4-c9da-ee090952b54e"
      },
      "source": [
        "encoded_text.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5441624,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iwaLjlN2WNW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fc6aa4c0-ed1e-47fc-f8a8-dfaf2b94cdd8"
      },
      "source": [
        "text[:500]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bud\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hI0-t5Wn2WNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "1aecd3fa-d97a-4e8b-8ba4-247a2856a154"
      },
      "source": [
        "encoded_text[:500]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64, 73,\n",
              "       60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,  1,\n",
              "       59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,  0,\n",
              "        1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57, 60,\n",
              "       56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63, 75,\n",
              "        1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76, 75,\n",
              "        1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63, 70,\n",
              "       76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60, 56,\n",
              "       74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,  1,\n",
              "       63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1, 63,\n",
              "       64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,  1,\n",
              "       75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1, 75,\n",
              "       70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62, 63,\n",
              "       75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74, 75,\n",
              "        1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56, 68,\n",
              "       60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74, 75,\n",
              "       56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38, 56,\n",
              "       66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63, 60,\n",
              "       73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60, 74,\n",
              "        8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,  1,\n",
              "       61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60, 75,\n",
              "        1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,  0,\n",
              "        1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1, 69,\n",
              "       70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61, 73,\n",
              "       60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1, 26,\n",
              "       69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75, 70,\n",
              "        1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69, 62,\n",
              "        8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,  1,\n",
              "       70, 78, 69,  1, 57, 76, 59])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYw4h5jX2WOZ",
        "colab_type": "text"
      },
      "source": [
        "### creating training batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vupRqRF12WOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#on the average for shakespere there are 41 character per line...alternate lines rhyme\n",
        "# to capture this we select 3 lines=120 characters...\n",
        "seq_len=120"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ssxt23p2WO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_num_seq=len(text)//(seq_len+1)#integer division....+1 for zero indexing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdaaXNPH2WPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b888971-8448-4561-a949-20183695a9c9"
      },
      "source": [
        "total_num_seq"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44972"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8Sza2gU2WP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#batch management function\n",
        "char_dataset=tf.data.Dataset.from_tensor_slices(encoded_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvrRHBOI2WQN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb670443-023e-4183-cdbc-441b4b529362"
      },
      "source": [
        "type(char_dataset)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "HW3qwjcq2WQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "outputId": "f21687db-414d-418a-b9e4-409bb428b0d2"
      },
      "source": [
        "for item in char_dataset.take(50):\n",
        "    print(item.numpy(),ind_to_char[item.numpy()])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "1  \n",
            "12 1\n",
            "0 \n",
            "\n",
            "1  \n",
            "1  \n",
            "31 F\n",
            "73 r\n",
            "70 o\n",
            "68 m\n",
            "1  \n",
            "61 f\n",
            "56 a\n",
            "64 i\n",
            "73 r\n",
            "60 e\n",
            "74 s\n",
            "75 t\n",
            "1  \n",
            "58 c\n",
            "73 r\n",
            "60 e\n",
            "56 a\n",
            "75 t\n",
            "76 u\n",
            "73 r\n",
            "60 e\n",
            "74 s\n",
            "1  \n",
            "78 w\n",
            "60 e\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7Tmgz5U2WRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = char_dataset.batch(seq_len+1,drop_remainder=True)#drop last remaining characters that cannot make up a sequence length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzdswmIl2WRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49006e5d-050f-4f57-b9ef-079610ae1f80"
      },
      "source": [
        "sequences"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: (121,), types: tf.int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8iQGmF72WR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_seq_targets(seq):\n",
        "    input_txt = seq[:-1] #hello my nam\n",
        "    target_txt = seq[1:] #ello my name\n",
        "    return input_txt,target_txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuxAyc9C2WSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset= sequences.map(create_seq_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZZjKYDo2WSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c259d359-00e9-4ef7-d9ae-545ac53e211e"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: ((120,), (120,)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G-Jwmpy2WSj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "f2ee84ea-3208-45f8-ab79-22cdb396926d"
      },
      "source": [
        "for input_text,output_text in dataset.take(1):\n",
        "    print(input_text.numpy())\n",
        "    print(\"\".join(ind_to_char[input_text.numpy()]))\n",
        "    print(\"\\n\\n\\n target seq \\n\\n\\n\")\n",
        "    print(output_text.numpy())\n",
        "    print(\"\".join(ind_to_char[output_text.numpy()]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n",
            "\n",
            "\n",
            "\n",
            " target seq \n",
            "\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1  1\n",
            " 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1 78\n",
            " 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63 56\n",
            " 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60  1\n",
            " 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1 56]\n",
            "                    1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0FuyR182WTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lul1q0Hp2WUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rebatching into 128 so we have 128 batches of 120 batches of input and target sequences!!! fantastic function\n",
        "buffer_size =10000 # memory management...so that we dont shuffle whole all seqs in mem at once!\n",
        "dataset =dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True) #we shuffle because we don't want to the model to learn a particular order i.e. we want to improve generalization...may or may not i guess...usecase specific"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GImKSIWK2WUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76171858-e0d2-47bc-a4b2-d385bd4189db"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msw9bw7x2WUg",
        "colab_type": "text"
      },
      "source": [
        "### building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8LU_Xwp2WUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBVRFx2P2WUu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91f46ae8-b68b-4139-a656-d31f7c3ee835"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZZS9m_h2WU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_dim = 64 # choose something in the same scale as your vocab_size--i think better smaller tha vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkFEjJWC2WVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_neurons = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYm_IUHN2WVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy #? investigate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgxcAtzi2WVX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "40101d99-1b11-4a7e-a36d-b34b04a74d07"
      },
      "source": [
        "help(sparse_categorical_crossentropy)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function sparse_categorical_crossentropy in module tensorflow.python.keras.losses:\n",
            "\n",
            "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQlKDoBw2WVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "    return sparse_categorical_crossentropy(y_true,y_pred,from_logits=True) # from logits=true because vocab is 1 hot encoded\n",
        "# on further research i think it has to do with nature of input into the func... the same thing really\n",
        "# https://stackoverflow.com/questions/41455101/what-is-the-meaning-of-the-word-logits-in-tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzSx5Qzb2WVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM,Embedding,GRU\n",
        "\n",
        "def create_model(vocab_size,embed_dim,rnn_neurons,batch_size):\n",
        "    model =Sequential()\n",
        "    model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[batch_size,None]))\n",
        "    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))# research recommends glorot...also read help text on GRU object\n",
        "    model.add(Dense(vocab_size))\n",
        "    model.compile('adam',loss=sparse_cat_loss) # this is why we had to wrap sparse_categorical_crossentropy in a function...to change the from logit arg to True\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtEPwKje2WVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model =create_model(vocab_size=vocab_size,embed_dim=embed_dim,\n",
        "                    rnn_neurons=rnn_neurons,batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO9FFVBa2WWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "fdb6290b-3a6d-4c1e-cbb6-af8ebdd71894"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (128, None, 64)           5376      \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (128, None, 1024)         3348480   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (128, None, 84)           86100     \n",
            "=================================================================\n",
            "Total params: 3,439,956\n",
            "Trainable params: 3,439,956\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JweS9m7IyljU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#just testing model before training to see we have everything lined up right\n",
        "for input_example_batch,target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions =model(input_example_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LisYuRLKza6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5aa81375-307a-40d8-c1c7-9321375d6a8e"
      },
      "source": [
        "example_batch_predictions.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([128, 120, 84])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwUFka3azE5C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "5ee46865-c053-4f28-a442-b05c85f231e2"
      },
      "source": [
        "example_batch_predictions[0] # these are probabilities the model ouputs for characters in our vocab"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 84), dtype=float32, numpy=\n",
              "array([[ 0.0025084 , -0.00144236, -0.0014917 , ...,  0.01476112,\n",
              "        -0.00629725,  0.0021914 ],\n",
              "       [-0.00170182,  0.00681937,  0.00352061, ...,  0.01420698,\n",
              "        -0.0014509 ,  0.00148135],\n",
              "       [-0.00468626,  0.00858257, -0.00057742, ...,  0.00433957,\n",
              "         0.00254682,  0.00089825],\n",
              "       ...,\n",
              "       [-0.00180556, -0.00236609,  0.00255352, ..., -0.00218934,\n",
              "         0.00089715, -0.00559134],\n",
              "       [ 0.00065914, -0.00624004, -0.00580815, ..., -0.01274909,\n",
              "         0.00342777, -0.00351468],\n",
              "       [ 0.00450021, -0.00166791, -0.00686431, ..., -0.00689683,\n",
              "         0.0064823 ,  0.00127538]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAuu_kB50GSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices=tf.random.categorical(example_batch_predictions[0],num_samples=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcRqKwDHzqHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "90a7de83-cc7b-40dd-f046-9b6a620cd79b"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
              "array([[25],\n",
              "       [18],\n",
              "       [28],\n",
              "       [72],\n",
              "       [83],\n",
              "       [17],\n",
              "       [81],\n",
              "       [49],\n",
              "       [52],\n",
              "       [48],\n",
              "       [26],\n",
              "       [21],\n",
              "       [55],\n",
              "       [10],\n",
              "       [37],\n",
              "       [72],\n",
              "       [ 6],\n",
              "       [31],\n",
              "       [68],\n",
              "       [79],\n",
              "       [ 3],\n",
              "       [ 3],\n",
              "       [81],\n",
              "       [52],\n",
              "       [63],\n",
              "       [53],\n",
              "       [56],\n",
              "       [66],\n",
              "       [33],\n",
              "       [23],\n",
              "       [20],\n",
              "       [80],\n",
              "       [ 2],\n",
              "       [72],\n",
              "       [73],\n",
              "       [42],\n",
              "       [71],\n",
              "       [78],\n",
              "       [75],\n",
              "       [19],\n",
              "       [47],\n",
              "       [53],\n",
              "       [ 6],\n",
              "       [34],\n",
              "       [63],\n",
              "       [26],\n",
              "       [56],\n",
              "       [68],\n",
              "       [70],\n",
              "       [13],\n",
              "       [71],\n",
              "       [59],\n",
              "       [75],\n",
              "       [82],\n",
              "       [61],\n",
              "       [ 9],\n",
              "       [67],\n",
              "       [76],\n",
              "       [40],\n",
              "       [80],\n",
              "       [48],\n",
              "       [59],\n",
              "       [55],\n",
              "       [61],\n",
              "       [41],\n",
              "       [35],\n",
              "       [53],\n",
              "       [23],\n",
              "       [64],\n",
              "       [66],\n",
              "       [75],\n",
              "       [68],\n",
              "       [ 4],\n",
              "       [67],\n",
              "       [17],\n",
              "       [40],\n",
              "       [40],\n",
              "       [37],\n",
              "       [73],\n",
              "       [17],\n",
              "       [46],\n",
              "       [78],\n",
              "       [83],\n",
              "       [63],\n",
              "       [32],\n",
              "       [41],\n",
              "       [81],\n",
              "       [82],\n",
              "       [53],\n",
              "       [41],\n",
              "       [ 4],\n",
              "       [32],\n",
              "       [ 8],\n",
              "       [68],\n",
              "       [63],\n",
              "       [ 8],\n",
              "       [63],\n",
              "       [78],\n",
              "       [ 3],\n",
              "       [74],\n",
              "       [ 8],\n",
              "       [44],\n",
              "       [69],\n",
              "       [78],\n",
              "       [ 1],\n",
              "       [59],\n",
              "       [71],\n",
              "       [78],\n",
              "       [82],\n",
              "       [14],\n",
              "       [49],\n",
              "       [82],\n",
              "       [61],\n",
              "       [41],\n",
              "       [50],\n",
              "       [78],\n",
              "       [40],\n",
              "       [ 4],\n",
              "       [62],\n",
              "       [ 7]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7-45JFW0m0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices=tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VufttHu1uF4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "f23ecf54-a100-4853-a928-64bd673613f9"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([25, 18, 28, 72, 83, 17, 81, 49, 52, 48, 26, 21, 55, 10, 37, 72,  6,\n",
              "       31, 68, 79,  3,  3, 81, 52, 63, 53, 56, 66, 33, 23, 20, 80,  2, 72,\n",
              "       73, 42, 71, 78, 75, 19, 47, 53,  6, 34, 63, 26, 56, 68, 70, 13, 71,\n",
              "       59, 75, 82, 61,  9, 67, 76, 40, 80, 48, 59, 55, 61, 41, 35, 53, 23,\n",
              "       64, 66, 75, 68,  4, 67, 17, 40, 40, 37, 73, 17, 46, 78, 83, 63, 32,\n",
              "       41, 81, 82, 53, 41,  4, 32,  8, 68, 63,  8, 63, 78,  3, 74,  8, 44,\n",
              "       69, 78,  1, 59, 71, 78, 82, 14, 49, 82, 61, 41, 50, 78, 40,  4, 62,\n",
              "        7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhLQkUdU1xc5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "a7491d5a-0fee-485b-b2ae-654903f0e32c"
      },
      "source": [
        "ind_to_char[sampled_indices]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['?', '7', 'C', 'q', '}', '6', 'z', 'X', '[', 'W', 'A', ':', '`',\n",
              "       '.', 'L', 'q', '(', 'F', 'm', 'x', '\"', '\"', 'z', '[', 'h', ']',\n",
              "       'a', 'k', 'H', '<', '9', 'y', '!', 'q', 'r', 'Q', 'p', 'w', 't',\n",
              "       '8', 'V', ']', '(', 'I', 'h', 'A', 'a', 'm', 'o', '2', 'p', 'd',\n",
              "       't', '|', 'f', '-', 'l', 'u', 'O', 'y', 'W', 'd', '`', 'f', 'P',\n",
              "       'J', ']', '<', 'i', 'k', 't', 'm', '&', 'l', '6', 'O', 'O', 'L',\n",
              "       'r', '6', 'U', 'w', '}', 'h', 'G', 'P', 'z', '|', ']', 'P', '&',\n",
              "       'G', ',', 'm', 'h', ',', 'h', 'w', '\"', 's', ',', 'S', 'n', 'w',\n",
              "       ' ', 'd', 'p', 'w', '|', '3', 'X', '|', 'f', 'P', 'Y', 'w', 'O',\n",
              "       '&', 'g', ')'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG930XXa19O9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "4fb6a8c5-c7ee-46a7-c214-1b80c20efad5"
      },
      "source": [
        "epochs=30\n",
        "model.fit(dataset,epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 351 steps\n",
            "Epoch 1/30\n",
            "351/351 [==============================] - 2979s 8s/step - loss: 2.5356\n",
            "Epoch 2/30\n",
            "351/351 [==============================] - 3004s 9s/step - loss: 1.7840\n",
            "Epoch 3/30\n",
            "144/351 [===========>..................] - ETA: 29:55 - loss: 1.5565"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH5q2QcI2NqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}