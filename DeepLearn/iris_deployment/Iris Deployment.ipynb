{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('../../../FINAL-TF2-FILES/TF_2_Notebooks_and_Data/DATA/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop =EarlyStopping(monitor='val_loss',patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 1s 11ms/sample - loss: 1.0744 - accuracy: 0.3500 - val_loss: 1.1677 - val_accuracy: 0.2667\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 1.0678 - accuracy: 0.3500 - val_loss: 1.1589 - val_accuracy: 0.2667\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 0s 550us/sample - loss: 1.0603 - accuracy: 0.3500 - val_loss: 1.1505 - val_accuracy: 0.2667\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 0s 817us/sample - loss: 1.0535 - accuracy: 0.3500 - val_loss: 1.1422 - val_accuracy: 0.2667\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 0s 582us/sample - loss: 1.0463 - accuracy: 0.3500 - val_loss: 1.1340 - val_accuracy: 0.2667\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 0s 347us/sample - loss: 1.0387 - accuracy: 0.3500 - val_loss: 1.1257 - val_accuracy: 0.2667\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 0s 398us/sample - loss: 1.0321 - accuracy: 0.3500 - val_loss: 1.1175 - val_accuracy: 0.2667\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 0s 412us/sample - loss: 1.0252 - accuracy: 0.3583 - val_loss: 1.1094 - val_accuracy: 0.2667\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 0s 697us/sample - loss: 1.0186 - accuracy: 0.3583 - val_loss: 1.1012 - val_accuracy: 0.2667\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 0s 446us/sample - loss: 1.0117 - accuracy: 0.3583 - val_loss: 1.0931 - val_accuracy: 0.3000\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 0s 506us/sample - loss: 1.0049 - accuracy: 0.3583 - val_loss: 1.0854 - val_accuracy: 0.3000\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 0s 720us/sample - loss: 0.9986 - accuracy: 0.3750 - val_loss: 1.0775 - val_accuracy: 0.3333\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 0s 810us/sample - loss: 0.9917 - accuracy: 0.3750 - val_loss: 1.0699 - val_accuracy: 0.3333\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 606us/sample - loss: 0.9857 - accuracy: 0.3750 - val_loss: 1.0622 - val_accuracy: 0.3333\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.9795 - accuracy: 0.3917 - val_loss: 1.0546 - val_accuracy: 0.3333\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.9725 - accuracy: 0.4167 - val_loss: 1.0472 - val_accuracy: 0.3333\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 0s 924us/sample - loss: 0.9660 - accuracy: 0.4250 - val_loss: 1.0398 - val_accuracy: 0.3333\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 0s 474us/sample - loss: 0.9590 - accuracy: 0.4417 - val_loss: 1.0319 - val_accuracy: 0.3667\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 494us/sample - loss: 0.9518 - accuracy: 0.4833 - val_loss: 1.0239 - val_accuracy: 0.3667\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 0s 505us/sample - loss: 0.9448 - accuracy: 0.5083 - val_loss: 1.0157 - val_accuracy: 0.4000\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 858us/sample - loss: 0.9376 - accuracy: 0.5417 - val_loss: 1.0076 - val_accuracy: 0.4000\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 663us/sample - loss: 0.9302 - accuracy: 0.5917 - val_loss: 0.9999 - val_accuracy: 0.4667\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 538us/sample - loss: 0.9233 - accuracy: 0.6083 - val_loss: 0.9920 - val_accuracy: 0.5000\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 513us/sample - loss: 0.9158 - accuracy: 0.6167 - val_loss: 0.9841 - val_accuracy: 0.5333\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 368us/sample - loss: 0.9081 - accuracy: 0.6417 - val_loss: 0.9761 - val_accuracy: 0.6000\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 430us/sample - loss: 0.9006 - accuracy: 0.6583 - val_loss: 0.9684 - val_accuracy: 0.6000\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 0s 437us/sample - loss: 0.8934 - accuracy: 0.6667 - val_loss: 0.9611 - val_accuracy: 0.6000\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 0s 427us/sample - loss: 0.8865 - accuracy: 0.6750 - val_loss: 0.9540 - val_accuracy: 0.6000\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 413us/sample - loss: 0.8801 - accuracy: 0.6833 - val_loss: 0.9471 - val_accuracy: 0.6000\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 640us/sample - loss: 0.8737 - accuracy: 0.6833 - val_loss: 0.9404 - val_accuracy: 0.6000\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 487us/sample - loss: 0.8680 - accuracy: 0.6833 - val_loss: 0.9341 - val_accuracy: 0.6000\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 0s 363us/sample - loss: 0.8621 - accuracy: 0.6833 - val_loss: 0.9279 - val_accuracy: 0.6000\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 644us/sample - loss: 0.8557 - accuracy: 0.6833 - val_loss: 0.9217 - val_accuracy: 0.6000\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.8500 - accuracy: 0.6833 - val_loss: 0.9155 - val_accuracy: 0.6000\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 463us/sample - loss: 0.8439 - accuracy: 0.6833 - val_loss: 0.9095 - val_accuracy: 0.6000\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 801us/sample - loss: 0.8380 - accuracy: 0.6833 - val_loss: 0.9036 - val_accuracy: 0.6000\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.8323 - accuracy: 0.6833 - val_loss: 0.8977 - val_accuracy: 0.6000\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 0s 782us/sample - loss: 0.8264 - accuracy: 0.6833 - val_loss: 0.8919 - val_accuracy: 0.6000\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 0s 419us/sample - loss: 0.8206 - accuracy: 0.6833 - val_loss: 0.8860 - val_accuracy: 0.6000\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 0s 659us/sample - loss: 0.8149 - accuracy: 0.6833 - val_loss: 0.8803 - val_accuracy: 0.6000\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 0s 740us/sample - loss: 0.8091 - accuracy: 0.6833 - val_loss: 0.8744 - val_accuracy: 0.6000\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 0s 680us/sample - loss: 0.8034 - accuracy: 0.6833 - val_loss: 0.8687 - val_accuracy: 0.6000\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 0s 531us/sample - loss: 0.7977 - accuracy: 0.6833 - val_loss: 0.8630 - val_accuracy: 0.6000\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 0s 442us/sample - loss: 0.7921 - accuracy: 0.6833 - val_loss: 0.8573 - val_accuracy: 0.6000\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 0s 477us/sample - loss: 0.7867 - accuracy: 0.6833 - val_loss: 0.8517 - val_accuracy: 0.6000\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 0s 472us/sample - loss: 0.7811 - accuracy: 0.6833 - val_loss: 0.8461 - val_accuracy: 0.6000\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 0s 378us/sample - loss: 0.7754 - accuracy: 0.6833 - val_loss: 0.8407 - val_accuracy: 0.6000\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 0s 478us/sample - loss: 0.7703 - accuracy: 0.6833 - val_loss: 0.8353 - val_accuracy: 0.6000\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 0s 383us/sample - loss: 0.7644 - accuracy: 0.6833 - val_loss: 0.8298 - val_accuracy: 0.6000\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 0s 397us/sample - loss: 0.7590 - accuracy: 0.6833 - val_loss: 0.8246 - val_accuracy: 0.6000\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 0s 383us/sample - loss: 0.7539 - accuracy: 0.6833 - val_loss: 0.8191 - val_accuracy: 0.6000\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - 0s 368us/sample - loss: 0.7485 - accuracy: 0.6833 - val_loss: 0.8137 - val_accuracy: 0.6000\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 0s 446us/sample - loss: 0.7434 - accuracy: 0.6833 - val_loss: 0.8083 - val_accuracy: 0.6000\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 0s 412us/sample - loss: 0.7382 - accuracy: 0.6833 - val_loss: 0.8030 - val_accuracy: 0.6000\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 0s 460us/sample - loss: 0.7329 - accuracy: 0.6833 - val_loss: 0.7979 - val_accuracy: 0.6000\n",
      "Epoch 56/300\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.7280 - accuracy: 0.6833 - val_loss: 0.7928 - val_accuracy: 0.6000\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 0s 468us/sample - loss: 0.7229 - accuracy: 0.6833 - val_loss: 0.7880 - val_accuracy: 0.6000\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 0s 380us/sample - loss: 0.7180 - accuracy: 0.6833 - val_loss: 0.7830 - val_accuracy: 0.6000\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 0s 466us/sample - loss: 0.7130 - accuracy: 0.6833 - val_loss: 0.7782 - val_accuracy: 0.6000\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 0s 454us/sample - loss: 0.7084 - accuracy: 0.6833 - val_loss: 0.7733 - val_accuracy: 0.6000\n",
      "Epoch 61/300\n",
      "120/120 [==============================] - 0s 462us/sample - loss: 0.7034 - accuracy: 0.6833 - val_loss: 0.7685 - val_accuracy: 0.6000\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 0s 569us/sample - loss: 0.6987 - accuracy: 0.6833 - val_loss: 0.7637 - val_accuracy: 0.6000\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 0s 502us/sample - loss: 0.6940 - accuracy: 0.6833 - val_loss: 0.7590 - val_accuracy: 0.6000\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 0s 584us/sample - loss: 0.6896 - accuracy: 0.6833 - val_loss: 0.7542 - val_accuracy: 0.6333\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 0s 399us/sample - loss: 0.6849 - accuracy: 0.6833 - val_loss: 0.7495 - val_accuracy: 0.6333\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 0s 541us/sample - loss: 0.6805 - accuracy: 0.6917 - val_loss: 0.7450 - val_accuracy: 0.6333\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 0s 388us/sample - loss: 0.6760 - accuracy: 0.6917 - val_loss: 0.7406 - val_accuracy: 0.6333\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - 0s 411us/sample - loss: 0.6717 - accuracy: 0.6917 - val_loss: 0.7362 - val_accuracy: 0.6333\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 0s 484us/sample - loss: 0.6674 - accuracy: 0.6917 - val_loss: 0.7318 - val_accuracy: 0.6333\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 0s 485us/sample - loss: 0.6632 - accuracy: 0.6917 - val_loss: 0.7276 - val_accuracy: 0.6333\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 0s 431us/sample - loss: 0.6591 - accuracy: 0.6917 - val_loss: 0.7234 - val_accuracy: 0.6333\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 0s 471us/sample - loss: 0.6550 - accuracy: 0.6917 - val_loss: 0.7193 - val_accuracy: 0.6333\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 0s 402us/sample - loss: 0.6507 - accuracy: 0.6917 - val_loss: 0.7152 - val_accuracy: 0.6333\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 0s 453us/sample - loss: 0.6467 - accuracy: 0.6917 - val_loss: 0.7111 - val_accuracy: 0.6333\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 0s 446us/sample - loss: 0.6427 - accuracy: 0.6917 - val_loss: 0.7072 - val_accuracy: 0.6333\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - 0s 523us/sample - loss: 0.6390 - accuracy: 0.6917 - val_loss: 0.7031 - val_accuracy: 0.6333\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 0s 415us/sample - loss: 0.6350 - accuracy: 0.6917 - val_loss: 0.6993 - val_accuracy: 0.6333\n",
      "Epoch 78/300\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.6312 - accuracy: 0.6917 - val_loss: 0.6955 - val_accuracy: 0.6333\n",
      "Epoch 79/300\n",
      "120/120 [==============================] - 0s 440us/sample - loss: 0.6274 - accuracy: 0.7000 - val_loss: 0.6918 - val_accuracy: 0.6333\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 0s 406us/sample - loss: 0.6238 - accuracy: 0.7000 - val_loss: 0.6879 - val_accuracy: 0.6333\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 0s 413us/sample - loss: 0.6200 - accuracy: 0.7000 - val_loss: 0.6841 - val_accuracy: 0.6333\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 0s 467us/sample - loss: 0.6164 - accuracy: 0.7000 - val_loss: 0.6805 - val_accuracy: 0.6333\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 0s 562us/sample - loss: 0.6129 - accuracy: 0.7000 - val_loss: 0.6767 - val_accuracy: 0.6333\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 0s 2ms/sample - loss: 0.6092 - accuracy: 0.7000 - val_loss: 0.6732 - val_accuracy: 0.6333\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.6059 - accuracy: 0.7000 - val_loss: 0.6696 - val_accuracy: 0.6333\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - 0s 541us/sample - loss: 0.6024 - accuracy: 0.7000 - val_loss: 0.6661 - val_accuracy: 0.6333\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 0s 591us/sample - loss: 0.5990 - accuracy: 0.7000 - val_loss: 0.6626 - val_accuracy: 0.6333\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 0s 360us/sample - loss: 0.5957 - accuracy: 0.7000 - val_loss: 0.6592 - val_accuracy: 0.6333\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 0s 380us/sample - loss: 0.5925 - accuracy: 0.7000 - val_loss: 0.6557 - val_accuracy: 0.6333\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 0s 394us/sample - loss: 0.5892 - accuracy: 0.7000 - val_loss: 0.6524 - val_accuracy: 0.6333\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 0.5860 - accuracy: 0.7000 - val_loss: 0.6491 - val_accuracy: 0.6333\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 0s 354us/sample - loss: 0.5829 - accuracy: 0.7000 - val_loss: 0.6458 - val_accuracy: 0.6333\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 0s 414us/sample - loss: 0.5798 - accuracy: 0.7000 - val_loss: 0.6427 - val_accuracy: 0.6333\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 0.5770 - accuracy: 0.7083 - val_loss: 0.6393 - val_accuracy: 0.6333\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 0s 317us/sample - loss: 0.5737 - accuracy: 0.7083 - val_loss: 0.6362 - val_accuracy: 0.6333\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 0s 418us/sample - loss: 0.5708 - accuracy: 0.7083 - val_loss: 0.6329 - val_accuracy: 0.6333\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 0s 423us/sample - loss: 0.5678 - accuracy: 0.7167 - val_loss: 0.6300 - val_accuracy: 0.6333\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 0s 437us/sample - loss: 0.5650 - accuracy: 0.7167 - val_loss: 0.6270 - val_accuracy: 0.6333\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 0s 384us/sample - loss: 0.5621 - accuracy: 0.7167 - val_loss: 0.6239 - val_accuracy: 0.6333\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 0s 405us/sample - loss: 0.5593 - accuracy: 0.7167 - val_loss: 0.6209 - val_accuracy: 0.6333\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 0s 372us/sample - loss: 0.5565 - accuracy: 0.7167 - val_loss: 0.6180 - val_accuracy: 0.6333\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 0s 609us/sample - loss: 0.5538 - accuracy: 0.7167 - val_loss: 0.6150 - val_accuracy: 0.6333\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 0s 437us/sample - loss: 0.5511 - accuracy: 0.7167 - val_loss: 0.6121 - val_accuracy: 0.6333\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 0s 345us/sample - loss: 0.5484 - accuracy: 0.7167 - val_loss: 0.6093 - val_accuracy: 0.6333\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 0s 409us/sample - loss: 0.5458 - accuracy: 0.7167 - val_loss: 0.6065 - val_accuracy: 0.6333\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 0s 374us/sample - loss: 0.5431 - accuracy: 0.7167 - val_loss: 0.6037 - val_accuracy: 0.6667\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 0s 389us/sample - loss: 0.5406 - accuracy: 0.7167 - val_loss: 0.6010 - val_accuracy: 0.6667\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 0s 435us/sample - loss: 0.5381 - accuracy: 0.7167 - val_loss: 0.5982 - val_accuracy: 0.6667\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 0s 397us/sample - loss: 0.5356 - accuracy: 0.7250 - val_loss: 0.5955 - val_accuracy: 0.6667\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 0s 466us/sample - loss: 0.5331 - accuracy: 0.7250 - val_loss: 0.5928 - val_accuracy: 0.6667\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 501us/sample - loss: 0.5307 - accuracy: 0.7333 - val_loss: 0.5902 - val_accuracy: 0.6667\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 0s 511us/sample - loss: 0.5283 - accuracy: 0.7333 - val_loss: 0.5878 - val_accuracy: 0.6667\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 0s 506us/sample - loss: 0.5259 - accuracy: 0.7417 - val_loss: 0.5853 - val_accuracy: 0.6667\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 0s 669us/sample - loss: 0.5236 - accuracy: 0.7417 - val_loss: 0.5827 - val_accuracy: 0.6667\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 0s 419us/sample - loss: 0.5212 - accuracy: 0.7417 - val_loss: 0.5801 - val_accuracy: 0.6667\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 0s 497us/sample - loss: 0.5190 - accuracy: 0.7417 - val_loss: 0.5776 - val_accuracy: 0.6667\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 0.5167 - accuracy: 0.7417 - val_loss: 0.5750 - val_accuracy: 0.6667\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 0s 462us/sample - loss: 0.5145 - accuracy: 0.7417 - val_loss: 0.5726 - val_accuracy: 0.6667\n",
      "Epoch 119/300\n",
      "120/120 [==============================] - 0s 471us/sample - loss: 0.5123 - accuracy: 0.7417 - val_loss: 0.5701 - val_accuracy: 0.6667\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 0.5102 - accuracy: 0.7417 - val_loss: 0.5675 - val_accuracy: 0.6667\n",
      "Epoch 121/300\n",
      "120/120 [==============================] - 0s 448us/sample - loss: 0.5079 - accuracy: 0.7417 - val_loss: 0.5652 - val_accuracy: 0.6667\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 0s 381us/sample - loss: 0.5057 - accuracy: 0.7417 - val_loss: 0.5629 - val_accuracy: 0.6667\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 0s 418us/sample - loss: 0.5037 - accuracy: 0.7417 - val_loss: 0.5605 - val_accuracy: 0.6667\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 0s 365us/sample - loss: 0.5017 - accuracy: 0.7417 - val_loss: 0.5580 - val_accuracy: 0.6667\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 0s 357us/sample - loss: 0.4996 - accuracy: 0.7417 - val_loss: 0.5556 - val_accuracy: 0.6667\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 0s 346us/sample - loss: 0.4975 - accuracy: 0.7500 - val_loss: 0.5534 - val_accuracy: 0.6667\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 0s 454us/sample - loss: 0.4955 - accuracy: 0.7583 - val_loss: 0.5513 - val_accuracy: 0.6667\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 0s 467us/sample - loss: 0.4935 - accuracy: 0.7583 - val_loss: 0.5490 - val_accuracy: 0.6667\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 0s 505us/sample - loss: 0.4914 - accuracy: 0.7667 - val_loss: 0.5467 - val_accuracy: 0.6667\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.4896 - accuracy: 0.7667 - val_loss: 0.5443 - val_accuracy: 0.7333\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 0s 464us/sample - loss: 0.4876 - accuracy: 0.7667 - val_loss: 0.5420 - val_accuracy: 0.7333\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 0s 534us/sample - loss: 0.4856 - accuracy: 0.7667 - val_loss: 0.5400 - val_accuracy: 0.7333\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - 0s 343us/sample - loss: 0.4838 - accuracy: 0.7667 - val_loss: 0.5379 - val_accuracy: 0.7667\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 0s 354us/sample - loss: 0.4819 - accuracy: 0.7750 - val_loss: 0.5358 - val_accuracy: 0.7667\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 0s 466us/sample - loss: 0.4801 - accuracy: 0.7750 - val_loss: 0.5337 - val_accuracy: 0.7667\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 0s 555us/sample - loss: 0.4783 - accuracy: 0.7917 - val_loss: 0.5316 - val_accuracy: 0.8000\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 0s 438us/sample - loss: 0.4765 - accuracy: 0.8000 - val_loss: 0.5296 - val_accuracy: 0.8000\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 0s 360us/sample - loss: 0.4746 - accuracy: 0.8000 - val_loss: 0.5276 - val_accuracy: 0.8000\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 0s 357us/sample - loss: 0.4729 - accuracy: 0.8083 - val_loss: 0.5257 - val_accuracy: 0.8000\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - 0s 478us/sample - loss: 0.4711 - accuracy: 0.8083 - val_loss: 0.5237 - val_accuracy: 0.8000\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 0s 478us/sample - loss: 0.4694 - accuracy: 0.8083 - val_loss: 0.5217 - val_accuracy: 0.8000\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 0s 446us/sample - loss: 0.4677 - accuracy: 0.8083 - val_loss: 0.5197 - val_accuracy: 0.8000\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 0s 385us/sample - loss: 0.4660 - accuracy: 0.8083 - val_loss: 0.5178 - val_accuracy: 0.8000\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 0s 428us/sample - loss: 0.4643 - accuracy: 0.8083 - val_loss: 0.5158 - val_accuracy: 0.8000\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 0s 370us/sample - loss: 0.4626 - accuracy: 0.8083 - val_loss: 0.5140 - val_accuracy: 0.8000\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 0s 373us/sample - loss: 0.4610 - accuracy: 0.8083 - val_loss: 0.5121 - val_accuracy: 0.8000\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 0s 421us/sample - loss: 0.4593 - accuracy: 0.8083 - val_loss: 0.5101 - val_accuracy: 0.8000\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 0s 459us/sample - loss: 0.4577 - accuracy: 0.8083 - val_loss: 0.5083 - val_accuracy: 0.8333\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 0s 316us/sample - loss: 0.4561 - accuracy: 0.8167 - val_loss: 0.5063 - val_accuracy: 0.8333\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 0s 497us/sample - loss: 0.4545 - accuracy: 0.8167 - val_loss: 0.5046 - val_accuracy: 0.8333\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 0s 470us/sample - loss: 0.4529 - accuracy: 0.8167 - val_loss: 0.5028 - val_accuracy: 0.8333\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 0s 334us/sample - loss: 0.4513 - accuracy: 0.8167 - val_loss: 0.5010 - val_accuracy: 0.8333\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 0s 306us/sample - loss: 0.4498 - accuracy: 0.8167 - val_loss: 0.4993 - val_accuracy: 0.8333\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 0s 391us/sample - loss: 0.4482 - accuracy: 0.8167 - val_loss: 0.4976 - val_accuracy: 0.8333\n",
      "Epoch 155/300\n",
      "120/120 [==============================] - 0s 366us/sample - loss: 0.4467 - accuracy: 0.8167 - val_loss: 0.4959 - val_accuracy: 0.8333\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 0s 391us/sample - loss: 0.4452 - accuracy: 0.8250 - val_loss: 0.4941 - val_accuracy: 0.8333\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 0s 361us/sample - loss: 0.4437 - accuracy: 0.8250 - val_loss: 0.4923 - val_accuracy: 0.8333\n",
      "Epoch 158/300\n",
      "120/120 [==============================] - 0s 387us/sample - loss: 0.4422 - accuracy: 0.8333 - val_loss: 0.4905 - val_accuracy: 0.8333\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 0s 494us/sample - loss: 0.4407 - accuracy: 0.8333 - val_loss: 0.4888 - val_accuracy: 0.8333\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 0s 541us/sample - loss: 0.4392 - accuracy: 0.8333 - val_loss: 0.4871 - val_accuracy: 0.8333\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 0s 626us/sample - loss: 0.4378 - accuracy: 0.8333 - val_loss: 0.4853 - val_accuracy: 0.8333\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 0s 745us/sample - loss: 0.4364 - accuracy: 0.8333 - val_loss: 0.4835 - val_accuracy: 0.8333\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 0s 880us/sample - loss: 0.4349 - accuracy: 0.8417 - val_loss: 0.4819 - val_accuracy: 0.8667\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 0s 624us/sample - loss: 0.4335 - accuracy: 0.8500 - val_loss: 0.4804 - val_accuracy: 0.8667\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 0s 370us/sample - loss: 0.4321 - accuracy: 0.8500 - val_loss: 0.4789 - val_accuracy: 0.8667\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 458us/sample - loss: 0.4307 - accuracy: 0.8500 - val_loss: 0.4772 - val_accuracy: 0.8667\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 0.4294 - accuracy: 0.8500 - val_loss: 0.4756 - val_accuracy: 0.8667\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 0s 366us/sample - loss: 0.4279 - accuracy: 0.8500 - val_loss: 0.4741 - val_accuracy: 0.8667\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 0s 347us/sample - loss: 0.4266 - accuracy: 0.8500 - val_loss: 0.4725 - val_accuracy: 0.8667\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 0s 370us/sample - loss: 0.4252 - accuracy: 0.8500 - val_loss: 0.4708 - val_accuracy: 0.8667\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 0s 405us/sample - loss: 0.4239 - accuracy: 0.8500 - val_loss: 0.4691 - val_accuracy: 0.8667\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 0s 376us/sample - loss: 0.4227 - accuracy: 0.8583 - val_loss: 0.4673 - val_accuracy: 0.9000\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 0s 441us/sample - loss: 0.4213 - accuracy: 0.8583 - val_loss: 0.4659 - val_accuracy: 0.9000\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 0s 321us/sample - loss: 0.4200 - accuracy: 0.8583 - val_loss: 0.4645 - val_accuracy: 0.9000\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.4187 - accuracy: 0.8583 - val_loss: 0.4629 - val_accuracy: 0.9000\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 0s 415us/sample - loss: 0.4175 - accuracy: 0.8583 - val_loss: 0.4613 - val_accuracy: 0.9000\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 0s 534us/sample - loss: 0.4161 - accuracy: 0.8583 - val_loss: 0.4600 - val_accuracy: 0.9000\n",
      "Epoch 178/300\n",
      "120/120 [==============================] - 0s 593us/sample - loss: 0.4148 - accuracy: 0.8583 - val_loss: 0.4587 - val_accuracy: 0.9000\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - 0s 415us/sample - loss: 0.4136 - accuracy: 0.8583 - val_loss: 0.4573 - val_accuracy: 0.9000\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 0s 474us/sample - loss: 0.4123 - accuracy: 0.8583 - val_loss: 0.4559 - val_accuracy: 0.9000\n",
      "Epoch 181/300\n",
      "120/120 [==============================] - 0s 590us/sample - loss: 0.4111 - accuracy: 0.8667 - val_loss: 0.4545 - val_accuracy: 0.9000\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 0s 337us/sample - loss: 0.4099 - accuracy: 0.8667 - val_loss: 0.4530 - val_accuracy: 0.9000\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 0s 380us/sample - loss: 0.4086 - accuracy: 0.8667 - val_loss: 0.4514 - val_accuracy: 0.9000\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 0s 391us/sample - loss: 0.4074 - accuracy: 0.8667 - val_loss: 0.4500 - val_accuracy: 0.9000\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 0s 341us/sample - loss: 0.4063 - accuracy: 0.8667 - val_loss: 0.4484 - val_accuracy: 0.9000\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 0s 501us/sample - loss: 0.4051 - accuracy: 0.8667 - val_loss: 0.4472 - val_accuracy: 0.9000\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 0s 364us/sample - loss: 0.4038 - accuracy: 0.8667 - val_loss: 0.4457 - val_accuracy: 0.9000\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 0s 337us/sample - loss: 0.4027 - accuracy: 0.8667 - val_loss: 0.4441 - val_accuracy: 0.9000\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 0s 551us/sample - loss: 0.4015 - accuracy: 0.8667 - val_loss: 0.4428 - val_accuracy: 0.9000\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 0s 448us/sample - loss: 0.4004 - accuracy: 0.8667 - val_loss: 0.4416 - val_accuracy: 0.9000\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 0s 411us/sample - loss: 0.3991 - accuracy: 0.8667 - val_loss: 0.4402 - val_accuracy: 0.9000\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 0s 368us/sample - loss: 0.3980 - accuracy: 0.8667 - val_loss: 0.4390 - val_accuracy: 0.9000\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 0s 538us/sample - loss: 0.3969 - accuracy: 0.8667 - val_loss: 0.4376 - val_accuracy: 0.9000\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 0s 569us/sample - loss: 0.3957 - accuracy: 0.8750 - val_loss: 0.4364 - val_accuracy: 0.9000\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 0s 435us/sample - loss: 0.3946 - accuracy: 0.8750 - val_loss: 0.4351 - val_accuracy: 0.9000\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 0.3935 - accuracy: 0.8833 - val_loss: 0.4338 - val_accuracy: 0.9000\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 0s 430us/sample - loss: 0.3923 - accuracy: 0.8833 - val_loss: 0.4327 - val_accuracy: 0.9000\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 0s 440us/sample - loss: 0.3913 - accuracy: 0.8833 - val_loss: 0.4316 - val_accuracy: 0.9000\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 0s 399us/sample - loss: 0.3902 - accuracy: 0.8833 - val_loss: 0.4303 - val_accuracy: 0.9000\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 0s 431us/sample - loss: 0.3890 - accuracy: 0.8833 - val_loss: 0.4290 - val_accuracy: 0.9000\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 0s 728us/sample - loss: 0.3880 - accuracy: 0.8917 - val_loss: 0.4278 - val_accuracy: 0.9000\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 0s 439us/sample - loss: 0.3869 - accuracy: 0.9000 - val_loss: 0.4265 - val_accuracy: 0.9333\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 0s 353us/sample - loss: 0.3858 - accuracy: 0.9000 - val_loss: 0.4253 - val_accuracy: 0.9333\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 0s 386us/sample - loss: 0.3849 - accuracy: 0.9083 - val_loss: 0.4239 - val_accuracy: 0.9333\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 0s 607us/sample - loss: 0.3837 - accuracy: 0.9083 - val_loss: 0.4227 - val_accuracy: 0.9333\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.3826 - accuracy: 0.9083 - val_loss: 0.4216 - val_accuracy: 0.9333\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - 0s 386us/sample - loss: 0.3816 - accuracy: 0.9083 - val_loss: 0.4205 - val_accuracy: 0.9333\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 0s 443us/sample - loss: 0.3806 - accuracy: 0.9167 - val_loss: 0.4191 - val_accuracy: 0.9333\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 0s 345us/sample - loss: 0.3797 - accuracy: 0.9167 - val_loss: 0.4176 - val_accuracy: 0.9333\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 0s 525us/sample - loss: 0.3785 - accuracy: 0.9167 - val_loss: 0.4167 - val_accuracy: 0.9333\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 0s 481us/sample - loss: 0.3775 - accuracy: 0.9167 - val_loss: 0.4155 - val_accuracy: 0.9333\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 0s 359us/sample - loss: 0.3764 - accuracy: 0.9167 - val_loss: 0.4143 - val_accuracy: 0.9333\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 0s 376us/sample - loss: 0.3754 - accuracy: 0.9167 - val_loss: 0.4132 - val_accuracy: 0.9333\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 0s 469us/sample - loss: 0.3744 - accuracy: 0.9167 - val_loss: 0.4122 - val_accuracy: 0.9333\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 0s 530us/sample - loss: 0.3734 - accuracy: 0.9167 - val_loss: 0.4112 - val_accuracy: 0.9333\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 0s 466us/sample - loss: 0.3724 - accuracy: 0.9167 - val_loss: 0.4100 - val_accuracy: 0.9333\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 0s 469us/sample - loss: 0.3714 - accuracy: 0.9167 - val_loss: 0.4088 - val_accuracy: 0.9333\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 0s 433us/sample - loss: 0.3704 - accuracy: 0.9167 - val_loss: 0.4076 - val_accuracy: 0.9333\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 0s 476us/sample - loss: 0.3695 - accuracy: 0.9167 - val_loss: 0.4065 - val_accuracy: 0.9333\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 0s 410us/sample - loss: 0.3685 - accuracy: 0.9167 - val_loss: 0.4055 - val_accuracy: 0.9333\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 388us/sample - loss: 0.3676 - accuracy: 0.9167 - val_loss: 0.4043 - val_accuracy: 0.9333\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 0s 389us/sample - loss: 0.3666 - accuracy: 0.9250 - val_loss: 0.4032 - val_accuracy: 0.9333\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 0s 397us/sample - loss: 0.3656 - accuracy: 0.9250 - val_loss: 0.4020 - val_accuracy: 0.9333\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 0s 510us/sample - loss: 0.3647 - accuracy: 0.9250 - val_loss: 0.4011 - val_accuracy: 0.9333\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 0s 400us/sample - loss: 0.3637 - accuracy: 0.9250 - val_loss: 0.4001 - val_accuracy: 0.9333\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.3628 - accuracy: 0.9250 - val_loss: 0.3990 - val_accuracy: 0.9333\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 0s 354us/sample - loss: 0.3618 - accuracy: 0.9250 - val_loss: 0.3978 - val_accuracy: 0.9333\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 0s 357us/sample - loss: 0.3609 - accuracy: 0.9250 - val_loss: 0.3967 - val_accuracy: 0.9667\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 0s 425us/sample - loss: 0.3599 - accuracy: 0.9250 - val_loss: 0.3956 - val_accuracy: 0.9667\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 0s 437us/sample - loss: 0.3590 - accuracy: 0.9250 - val_loss: 0.3946 - val_accuracy: 0.9667\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - 0s 512us/sample - loss: 0.3581 - accuracy: 0.9250 - val_loss: 0.3936 - val_accuracy: 0.9667\n",
      "Epoch 232/300\n",
      "120/120 [==============================] - 0s 453us/sample - loss: 0.3571 - accuracy: 0.9250 - val_loss: 0.3926 - val_accuracy: 0.9667\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 0s 662us/sample - loss: 0.3563 - accuracy: 0.9250 - val_loss: 0.3917 - val_accuracy: 0.9667\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 0s 518us/sample - loss: 0.3553 - accuracy: 0.9250 - val_loss: 0.3906 - val_accuracy: 0.9667\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 0s 520us/sample - loss: 0.3544 - accuracy: 0.9250 - val_loss: 0.3895 - val_accuracy: 0.9667\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - 0s 545us/sample - loss: 0.3537 - accuracy: 0.9250 - val_loss: 0.3882 - val_accuracy: 0.9667\n",
      "Epoch 237/300\n",
      "120/120 [==============================] - 0s 416us/sample - loss: 0.3527 - accuracy: 0.9250 - val_loss: 0.3873 - val_accuracy: 0.9667\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 0s 430us/sample - loss: 0.3518 - accuracy: 0.9250 - val_loss: 0.3865 - val_accuracy: 0.9667\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 0s 405us/sample - loss: 0.3508 - accuracy: 0.9250 - val_loss: 0.3855 - val_accuracy: 0.9667\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - 0s 380us/sample - loss: 0.3500 - accuracy: 0.9250 - val_loss: 0.3843 - val_accuracy: 0.9667\n",
      "Epoch 241/300\n",
      "120/120 [==============================] - 0s 477us/sample - loss: 0.3490 - accuracy: 0.9250 - val_loss: 0.3832 - val_accuracy: 0.9667\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 0s 428us/sample - loss: 0.3481 - accuracy: 0.9250 - val_loss: 0.3823 - val_accuracy: 0.9667\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 0s 386us/sample - loss: 0.3473 - accuracy: 0.9250 - val_loss: 0.3814 - val_accuracy: 0.9667\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 0s 352us/sample - loss: 0.3465 - accuracy: 0.9250 - val_loss: 0.3803 - val_accuracy: 0.9667\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 0s 327us/sample - loss: 0.3456 - accuracy: 0.9250 - val_loss: 0.3796 - val_accuracy: 0.9667\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 0.3447 - accuracy: 0.9250 - val_loss: 0.3787 - val_accuracy: 0.9667\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 0s 377us/sample - loss: 0.3438 - accuracy: 0.9250 - val_loss: 0.3777 - val_accuracy: 0.9667\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 0s 655us/sample - loss: 0.3430 - accuracy: 0.9250 - val_loss: 0.3766 - val_accuracy: 0.9667\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 0s 662us/sample - loss: 0.3422 - accuracy: 0.9250 - val_loss: 0.3758 - val_accuracy: 0.9667\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 0s 396us/sample - loss: 0.3412 - accuracy: 0.9250 - val_loss: 0.3746 - val_accuracy: 0.9667\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 0s 386us/sample - loss: 0.3404 - accuracy: 0.9250 - val_loss: 0.3734 - val_accuracy: 0.9667\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 0s 360us/sample - loss: 0.3395 - accuracy: 0.9250 - val_loss: 0.3722 - val_accuracy: 0.9667\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 0s 401us/sample - loss: 0.3387 - accuracy: 0.9333 - val_loss: 0.3712 - val_accuracy: 0.9667\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 0s 394us/sample - loss: 0.3378 - accuracy: 0.9250 - val_loss: 0.3704 - val_accuracy: 0.9667\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 0s 387us/sample - loss: 0.3370 - accuracy: 0.9250 - val_loss: 0.3697 - val_accuracy: 0.9667\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 0s 526us/sample - loss: 0.3362 - accuracy: 0.9250 - val_loss: 0.3689 - val_accuracy: 0.9667\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 0s 460us/sample - loss: 0.3353 - accuracy: 0.9250 - val_loss: 0.3680 - val_accuracy: 0.9667\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 0s 402us/sample - loss: 0.3345 - accuracy: 0.9250 - val_loss: 0.3671 - val_accuracy: 0.9667\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.3337 - accuracy: 0.9250 - val_loss: 0.3660 - val_accuracy: 0.9667\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 0s 386us/sample - loss: 0.3328 - accuracy: 0.9417 - val_loss: 0.3650 - val_accuracy: 0.9667\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 0s 425us/sample - loss: 0.3321 - accuracy: 0.9333 - val_loss: 0.3638 - val_accuracy: 0.9667\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 0.3312 - accuracy: 0.9417 - val_loss: 0.3631 - val_accuracy: 0.9667\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 0s 380us/sample - loss: 0.3304 - accuracy: 0.9417 - val_loss: 0.3621 - val_accuracy: 0.9667\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - 0s 410us/sample - loss: 0.3297 - accuracy: 0.9333 - val_loss: 0.3612 - val_accuracy: 0.9667\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 0s 377us/sample - loss: 0.3287 - accuracy: 0.9333 - val_loss: 0.3606 - val_accuracy: 0.9667\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 0s 403us/sample - loss: 0.3280 - accuracy: 0.9417 - val_loss: 0.3598 - val_accuracy: 0.9667\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 0s 356us/sample - loss: 0.3271 - accuracy: 0.9417 - val_loss: 0.3589 - val_accuracy: 0.9667\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 0s 774us/sample - loss: 0.3263 - accuracy: 0.9417 - val_loss: 0.3581 - val_accuracy: 0.9667\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 0s 635us/sample - loss: 0.3255 - accuracy: 0.9417 - val_loss: 0.3574 - val_accuracy: 0.9667\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 0s 413us/sample - loss: 0.3247 - accuracy: 0.9417 - val_loss: 0.3566 - val_accuracy: 0.9667\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 0s 334us/sample - loss: 0.3240 - accuracy: 0.9417 - val_loss: 0.3557 - val_accuracy: 0.9667\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 0s 314us/sample - loss: 0.3231 - accuracy: 0.9417 - val_loss: 0.3547 - val_accuracy: 0.9667\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - 0s 410us/sample - loss: 0.3223 - accuracy: 0.9417 - val_loss: 0.3537 - val_accuracy: 0.9667\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 0s 472us/sample - loss: 0.3215 - accuracy: 0.9417 - val_loss: 0.3528 - val_accuracy: 0.9667\n",
      "Epoch 275/300\n",
      "120/120 [==============================] - 0s 557us/sample - loss: 0.3208 - accuracy: 0.9417 - val_loss: 0.3520 - val_accuracy: 0.9667\n",
      "Epoch 276/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 353us/sample - loss: 0.3201 - accuracy: 0.9417 - val_loss: 0.3509 - val_accuracy: 0.9667\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 0s 605us/sample - loss: 0.3192 - accuracy: 0.9333 - val_loss: 0.3499 - val_accuracy: 0.9667\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 0s 395us/sample - loss: 0.3185 - accuracy: 0.9333 - val_loss: 0.3492 - val_accuracy: 0.9667\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 0s 312us/sample - loss: 0.3177 - accuracy: 0.9333 - val_loss: 0.3483 - val_accuracy: 0.9667\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 0s 413us/sample - loss: 0.3170 - accuracy: 0.9333 - val_loss: 0.3472 - val_accuracy: 0.9667\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 0s 547us/sample - loss: 0.3161 - accuracy: 0.9333 - val_loss: 0.3463 - val_accuracy: 0.9667\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - 0s 360us/sample - loss: 0.3154 - accuracy: 0.9333 - val_loss: 0.3456 - val_accuracy: 0.9667\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 0s 398us/sample - loss: 0.3146 - accuracy: 0.9333 - val_loss: 0.3446 - val_accuracy: 0.9667\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 0s 514us/sample - loss: 0.3139 - accuracy: 0.9333 - val_loss: 0.3437 - val_accuracy: 0.9667\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 0s 531us/sample - loss: 0.3130 - accuracy: 0.9333 - val_loss: 0.3429 - val_accuracy: 0.9667\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - 0s 479us/sample - loss: 0.3123 - accuracy: 0.9333 - val_loss: 0.3424 - val_accuracy: 0.9667\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 0s 703us/sample - loss: 0.3115 - accuracy: 0.9333 - val_loss: 0.3417 - val_accuracy: 0.9667\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 0s 615us/sample - loss: 0.3108 - accuracy: 0.9417 - val_loss: 0.3410 - val_accuracy: 0.9667\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - 0s 568us/sample - loss: 0.3101 - accuracy: 0.9333 - val_loss: 0.3401 - val_accuracy: 0.9667\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 0s 513us/sample - loss: 0.3093 - accuracy: 0.9417 - val_loss: 0.3393 - val_accuracy: 0.9667\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 0s 517us/sample - loss: 0.3086 - accuracy: 0.9417 - val_loss: 0.3384 - val_accuracy: 0.9667\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - 0s 711us/sample - loss: 0.3079 - accuracy: 0.9333 - val_loss: 0.3373 - val_accuracy: 0.9667\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 0s 399us/sample - loss: 0.3071 - accuracy: 0.9333 - val_loss: 0.3363 - val_accuracy: 0.9667\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 0s 337us/sample - loss: 0.3063 - accuracy: 0.9333 - val_loss: 0.3355 - val_accuracy: 0.9667\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 0s 377us/sample - loss: 0.3056 - accuracy: 0.9333 - val_loss: 0.3347 - val_accuracy: 0.9667\n",
      "Epoch 296/300\n",
      "120/120 [==============================] - 0s 436us/sample - loss: 0.3048 - accuracy: 0.9333 - val_loss: 0.3340 - val_accuracy: 0.9667\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - 0s 430us/sample - loss: 0.3042 - accuracy: 0.9333 - val_loss: 0.3332 - val_accuracy: 0.9667\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 0s 339us/sample - loss: 0.3034 - accuracy: 0.9333 - val_loss: 0.3323 - val_accuracy: 0.9667\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 0s 444us/sample - loss: 0.3026 - accuracy: 0.9333 - val_loss: 0.3315 - val_accuracy: 0.9667\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 0s 433us/sample - loss: 0.3020 - accuracy: 0.9333 - val_loss: 0.3307 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4ff06d0e50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train,y=y_train,epochs=300,\n",
    "          validation_data=(scaled_X_test,y_test),callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics =pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fe06926d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD6CAYAAACxrrxPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3xUVf7/8deZVEISSEhIh5BQAiTU0CWCiCAWVERxFZRV8Yti2VV+6qq7rmV3XdfVtbKoWBFBxa5gw6WXhJqQ0FsaSSCNhPTz++MOGJEkk2RKZvJ5Ph7zgMzcO/O5jr69Offcz1Faa4QQQjg/k6MLEEIIYR0S6EII4SIk0IUQwkVIoAshhIuQQBdCCBchgS6EEC6iyUBXSi1SSuUppVIbeP1GpdRO82O9Umqg9csUQgjRFNXUPHSlVBJwCnhXax1/ntdHA+la60Kl1KXA41rrEU19cFBQkI6Ojm5Z1UII0U6lpKQUaK2Dz/eae1M7a61XK6WiG3l9fb0fNwKRlhQVHR1NcnKyJZsKIYQwU0odaeg1a4+h3wp8a+X3FEIIYYEmz9AtpZQajxHoFzSyzRxgDkC3bt2s9dFCCCGw0hm6UmoA8AYwVWt9oqHttNYLtdaJWuvE4ODzDgEJIYRooVafoSulugHLgZla672tL0kI4cqqq6vJzMykoqLC0aW0ad7e3kRGRuLh4WHxPk0GulJqCTAOCFJKZQJ/ATwAtNYLgD8DXYBXlVIANVrrxGZXL4RoFzIzM/Hz8yM6OhpzZohzaK05ceIEmZmZ9OjRw+L9LJnlckMTr98G3GbxJwoh2rWKigoJ8yYopejSpQv5+fnN2k/uFBVC2J2EedNa8s/IcYFemuuwjxZCCFfkwEDPgWNbHPbxQoj2y9fX19El2ITjAt3NA1Y8CHV1DitBCCFcieMC3S8cslJg51KHlSCEaN+01syfP5/4+HgSEhJYutTIo5ycHJKSkhg0aBDx8fGsWbOG2tpabrnllrPbPv/88w6u/resdqdos/kEQkQ0/PA49L0CvFzzVyAhRMP++mUau7NLrPqe/cL9+csV/S3advny5Wzfvp0dO3ZQUFDAsGHDSEpK4oMPPmDSpEk88sgj1NbWUl5ezvbt28nKyiI11Wg8W1RUZNW6rcGxs1wmPwOncmHtvx1ahhCifVq7di033HADbm5uhISEcOGFF7JlyxaGDRvGW2+9xeOPP86uXbvw8/MjJiaGgwcPcvfdd7NixQr8/f0dXf5vOO4MHSBqGAy4Hta/DINnQqDlE+iFEM7P0jNpW2mofXhSUhKrV6/m66+/ZubMmcyfP59Zs2axY8cOVq5cySuvvMKyZctYtGiRnStunOPnoV/8OJjcYcXDjq5ECNHOJCUlsXTpUmpra8nPz2f16tUMHz6cI0eO0LVrV26//XZuvfVWtm7dSkFBAXV1dUybNo0nn3ySrVu3Orr833DsGTqAfziMewi+fwz2fAt9LnV0RUKIduLqq69mw4YNDBw4EKUU//znPwkNDeWdd97h2WefxcPDA19fX959912ysrKYPXs2deaZeX//+98dXP1vNblika0kJibqswtc1FbDgguguhzu3ASePg6pSQhhe+np6fTt29fRZTiF8/2zUkqlNNQvy/FDLmDMSZ/yLyg6Cmvb3lQgIYRwBm0j0AF6jIWE62DdC3DigKOrEUIIp9N2Ah3gkifB3Ru+mQ8OGgoSQghn1bYC3S8Uxv8JDvwI6V86uhohhHAqbSvQAYbdDiHxxjTGqjJHVyOEEE6j7QW6mztc9hyUZMLqZx1djRBCOI22F+gA3UbCoBuNO0jzZZlSIYSwRNsMdICL/2rMR//mfrlAKoRwmMZ6px8+fJj4+Hg7VtO4thvovsFw0WNwaDWkLXd0NUII0eY5/tb/xiT+Hra9DysfgZ4TwbvtdTcTQrTCtw9B7i7rvmdoAlz6jwZffvDBB+nevTt33nknAI8//jhKKVavXk1hYSHV1dU89dRTTJ06tVkfW1FRwdy5c0lOTsbd3Z1///vfjB8/nrS0NGbPnk1VVRV1dXV88sknhIeHc91115GZmUltbS2PPfYY119/fasOG9ryGTqAyQ0u/7ex/uiPTzi6GiGEC5gxY8bZhSwAli1bxuzZs/n000/ZunUrq1at4v7772+wE2NDXnnlFQB27drFkiVLuPnmm6moqGDBggXce++9bN++neTkZCIjI1mxYgXh4eHs2LGD1NRUJk+ebJVjc9gZenlVjWUbRgyFEXfApv/CgOsgarhtCxNC2E8jZ9K2MnjwYPLy8sjOziY/P5+AgADCwsL4wx/+wOrVqzGZTGRlZXH8+HFCQ0Mtft+1a9dy9913AxAXF0f37t3Zu3cvo0aN4umnnyYzM5NrrrmGXr16kZCQwAMPPMCDDz7I5ZdfztixY61ybA47Qz9UUM7RE+WWbXzRo+AfAV/cAzVVti1MCOHyrr32Wj7++GOWLl3KjBkzWLx4Mfn5+aSkpLB9+3ZCQkKoqKho1ns2dEb/u9/9ji+++IIOHTowadIkfvrpJ3r37k1KSgoJCQk8/PDDPPGEdUYgHDrk8sdl26mts+DXGi8/Y+glP93o9SKEEK0wY8YMPvzwQz7++GOuvfZaiouL6dq1Kx4eHqxatYojR440+z2TkpJYvHgxAHv37uXo0aP06dOHgwcPEhMTwz333MOVV17Jzp07yc7OxsfHh5tuuokHHnjAar3VHRboEZ29ST5SyIL/WdiIq/ck6H+NcbNRwT7bFieEcGn9+/entLSUiIgIwsLCuPHGG0lOTiYxMZHFixcTFxfX7Pe88847qa2tJSEhgeuvv563334bLy8vli5dSnx8PIMGDSIjI4NZs2axa9cuhg8fzqBBg3j66ad59NFHrXJcDu2HPuKPC1mZmstnd40hPqJT0zudyoOXh0FIf7j5KzC17Wu6Qojfkn7olnOqfuhPXxVPF19P7v1wG6erapvewbcrXPIUHFkHW9+xfYFCCOFEHBronX08eW76IA7kl/GPb9Mt22nwTRA9Fr7/M5Rk27ZAIYTAmIo4aNCgXz1GjBjh6LJ+w+E3Fl3QK4jZY6J5a91hJvQNIal3cOM7KAVX/AdeGwNf3w8zPjCeE0I4Da01yon+u01ISGD79u12/cyWDIe3iUHoByfHERvckYeX76Ks0oL56V1i4aJHYM83kPap7QsUQliNt7c3J06caFFgtRdaa06cOIG3t3ez9msbi0QDWw6fZPqCDdw0shtPXZXQ9BvU1sCbE411SOdtAZ9AG1YrhLCW6upqMjMzmz3Pu73x9vYmMjISDw+PXz3f2EVRhw+5nDEsOpDbLujBG2sPkdQrmEv6N3GHlps7TH0Z/psEKx6Caxbap1AhRKt4eHjQo0cPR5fhktrEkMsZ8yf3IT7Cn//3yU5yik83vUNIf7jgj7BzKRxYZfsChRCiDWtTge7l7saLMwZTVVPHH5ZaeBfp2PshMNa4QFotv8IJIdqvNhXoADHBvjwxNZ6NB0/y2s/7m97Bw9tYsu7kAVj7vO0LFEKINqrNBTrAtCERTB0UzvM/7CPlyMmmd4gdDwnTYe2/ocCC/wkIIYQLajLQlVKLlFJ5SqnUBl5XSqkXlVL7lVI7lVJDWluUUoqnroonvLM39yzZTvHp6qZ3uuRpcO8AX/9RlqwTQrRLlpyhvw001n39UqCX+TEHeK31ZYGftwcvzhjM8ZIKHvpkZ9NzVv1C4OK/wKH/wa6PrFGCEEI4lSYDXWu9Gmhs3GMq8K42bAQ6K6XCrFHc4G4BzJ/Uh29Tc1m86WjTOwydDRGJsPJPcLrQGiUIIYTTsMYYegRwrN7PmebnrOL2sTGM6xPME1/tJj2npPGNTSa4/HkoPylL1gkh2h1rBPr5GjKcd3xEKTVHKZWslErOz8+36M1NJsW/pg+kcwcP5n2wteml68IGwMi5kPwWHNti0WcIIYQrsEagZwJR9X6OBM7bBlFrvVBrnai1TgwObqIJVz1Bvl68cP0gDhaU8eAnu5oeTx/3EPiHw1f3GS0ChBCiHbBGoH8BzDLPdhkJFGutc6zwvr8yumcQ8yf14csd2SxcfbDxjb384NJn4HgqbFpg7VKEEKJNarKXi1JqCTAOCFJKZQJ/ATwAtNYLgG+AKcB+oByYbati514YS1pWCc+syKBvmH/jrXbjLofek2HV36DfVOgc1fC2QgjhAtpMt0VLlVfVcPUr6zlRVsXK+8bSxder4Y2LjsIrIyD2IpixuBXVCiFE29Bml6BrCR9Pd16YMYiS09U88mlq4+PpnbvBhQ9CxleQ8Y39ihRCCAdwukAH6Bvmz/2X9GZFWi7Lt2Y1vvGou6BrP/hmPlQU26dAIYRwAKcMdIDbxsYwPDqQv3yRRmZhecMbunnAlS9BaTaseNh+BQohhJ05baC7mRTPXTcQrTUPfLSDusZa7UYmGm12ty+G9K/sV6QQQtiR0wY6QFSgD3+5oj8bD55k0bpDjW+c9P8gdAB8eS+csuymJiGEcCZOHegA0xMjmdgvhH+u3MOe3NKGN3T3NJapqyw1Ql06MgohXIzTB7pSir9fk4C/tzv3Ld1OVU1dwxt37QsT/gx7vobkRfYrUggh7MDpAx2M1gB/v2YA6TklvPDD3sY3HnknxE4wFpbO3mafAoUQwg5cItABJvYL4brESBb870DjqxyZTHDN69CxKyybZXRmFEIIF+AygQ7w5yv6ExHQgT8s3UFZZSNNuTp2gevegZIc+Gwu1DUyTCOEEE7CpQLd18ud56YP4lhhOU99vbvxjSMTYdLfYO8KYy1SIYRwci4V6ADDewQyJymGJZuP8WP68SY2vt1YXPqnp2DvSvsUKIQQNuJygQ7wx4m9iQv148FPdnHiVGXDGyoFV7xoLIrxyW2Q38QFVSGEaMNcMtC93N14/nqjgdejn6U2vrGnD1y/GNw84cMb4HSRfYoUQggrc8lAB6OB130Te/Ftai7f7GpivY3OUXD9e1B42DhTr6u1S41CCGFNLhvoAHPGxpAQ0YnHPkvlZFlV4xt3Hw1TnoX938sC00IIp+TSge7uZuLZ6QMoqajmr1+mNb1D4u+Nx7oXYNfHti9QCCGsyKUDHSAu1J9543vx+fZsvt/dxKwXgMnPQLfR8Pk8yNpq+wKFEMJKXD7QAeaOiyUu1I9HPt3V9NCLuydc9y50DIYlN0Bxpn2KFEKIVmoXge7pbuK56wZSVF7N/I92NL5sHYBvMNy4DKrL4YMZRodGIYRo49pFoAP0D+/En6bE8WNGHm+ubaJ3OhidGae/BXm74eNbobaRVgJCCNEGtJtAB7h5dDQT+4XwzIoMth0tbHqHnhfDlH/CvpXw3SO2L1AIIVqhXQW6Uopnrx1AaCdv/u/9FPJKKpreadhtMPIu2LQANi20fZFCCNFC7SrQATr7eLJwZiIlp2u44/0UKmssuInokiehzxRY8SDs/c72RQohRAu0u0AH4y7S564byLajRTz6aWrTF0lNbkYP9ZB4+Hg25DbRTkAIIRygXQY6wJSEMO6Z0IuPUjJZuPpg0zt4+cLvloKXH3xwPZRaMKddCCHsqN0GOsB9E3px2YAw/rEig+/ScpvewT/cCPXTJ2HJDKgqt32RQghhoXYd6CaT4rnpAxkQ2Zl7P9xOWnZx0zuFDYRpbxrrkX56h6x2JIRoM9p1oAN4e7jx+syhdPbx4LZ3ki2b+RI3xVjtKP0LWPknaGoMXggh7KDdBzpAV39v3rg5keLT1dz+XgoV1RbMfBk5F0beCZteM5p5CSGEg0mgm/UP78QL1w9iZ2YR93+0g7q6Js66lYJLnob4a+GHx2HbYrvUKYQQDZFAr+eS/qE8ODmOr3fm8MKP+5rewWSCq16DmPHwxd2yLqkQwqEk0M9xR1IM04dG8uKP+/h8e1bTO7h7GqsdhSbAspvh2BbbFymEEOchgX4OpRRPX53A8B6BzP94J1st6fni5Qc3fgx+ofDBdMjfY/tChRDiHBLo5+HpbmLBTUMJ9fdmzrvJZBZaMN/cNxhmLgeTB7x3DZRk275QIYSoRwK9AYEdPVl0SyKVNXXc9k4ypyotaJ8bGAM3fQwVxfD+NDhtwdm9EEJYiQR6I3p29eOV3w1hX94p7l2yjdqmZr6AcePRjMVQsM9Y8UjuJhVC2IlFga6UmqyU2qOU2q+Ueug8r3dTSq1SSm1TSu1USk2xfqmOkdQ7mMev6MePGXn849t0y3aKuRCuWQhHN8KyWVDTxLJ3QghhBU0GulLKDXgFuBToB9yglOp3zmaPAsu01oOBGcCr1i7UkWaOiubmUd15fc0hPtx81LKd4q+By5+H/d/D8tuhzoKblYQQohUsOUMfDuzXWh/UWlcBHwJTz9lGA/7mv3cCXO6K4GOX9yOpdzCPfpbK+gMFlu2UOBsmPgm7P4Mv75UWAUIIm7Ik0COAY/V+zjQ/V9/jwE1KqUzgG+Du872RUmqOUipZKZWcn5/fgnIdx93NxMu/G0x0UEfmvr+VQwVllu045h5Img/b3oPvHpVQF0LYjCWBrs7z3LmpdAPwttY6EpgCvKeU+s17a60Xaq0TtdaJwcHBza/Wwfy9PVh08zBMCm59ewuFZRaOjY9/BIbfARtehlVPS6gLIWzCkkDPBKLq/RzJb4dUbgWWAWitNwDeQJA1CmxrunXxYeGsRDKLTjP77S2UV1kwnVEpmPwPGDILVj9r9H6RUBdCWJklgb4F6KWU6qGU8sS46PnFOdscBSYAKKX6YgS6c42pNMOw6EBeumEwOzOLmPv+VqprLeiJbjLB5f+BxFuN7ozSdlcIYWVNBrrWugaYB6wE0jFms6QppZ5QSl1p3ux+4Hal1A5gCXCLbnKhTuc2qX8of7s6gf/tzWe+Jd0ZwQj1y56DEXNh46vwzQOyQIYQwmrcLdlIa/0NxsXO+s/9ud7fdwNjrFta2zdjeDdOlFXx7Mo9dPH14tHL+qLU+S451KMUTP47uHnA+hehtso4czfJPV5CiNaxKNBFw+4cF0t+aSVvrj1EkK8Xc8fFNr2TUjDxCXDzhDX/gtoamPoymNxsX7AQwmVJoLeSUoo/X96Pk2VVPLMigy4dPbluWJQlO8KEx8Ddy5j5UlcNVy0AN/lKhBAtI+lhBSaT4l/TB1JYXsVDy3cS0NGTif1CLNv5wv8HJnf48a9QWw3T3jCGY4QQoplk4NZKzrTcTYjszLwPtrL50EnLdx77R2M5u92fGYtk1FTarlAhhMuSQLeijl7uvHXLMCICOnDrO1vIyC2xfOfR8+DSZ2HP17D0JqiusF2hQgiXJIFuZYEdPXn398Pp6OnOrDc3c+xkM9rnjpgDl78A+76DJTOk9a4Qolkk0G0gMsCHd28dTmVNHbMWbabgVDOGUBJnw9RX4ODPskiGEKJZJNBtpHeIH4tuSSSn+DSz39pi2YpHZwy+ybg4mrkF3pwERRa27BVCtGsS6DY0tHsgr944hN05JdzxXjKVNc3oiZ5wLcz8FEpz4Y2LIWeH7QoVQrgECXQbuyguhGemDWDd/hPctXgbVTXNuNW/x1i4daWx8PRbU2D/D7YrVAjh9CTQ7eDaoZE8MbU/P6Qf587FW5sX6l37wm0/QEAPWHwdbHvfdoUKIZyaBLqdzBoVzZNnQz2leaHuHwazv4EeSfD5XUb7XWnqJYQ4hwS6Hc08G+p53Lk4pXlj6t7+cONHMORmWPs8fHgDVDRjnrsQwuVJoNvZzFHRPHlVPD+k53HX4q3NC3U3D7jiPzDlX7Dve+Ni6YkDtitWCOFUJNAdYObI7mdD/c73mxnqSsHw240ZMGV58PpFcGCV7YoVQjgNCXQHmTmyO09dFc+PGS0IdYCYC+H2VeAXZtyAtHGBrIAkRDsnge5AN9UL9bktCfXAHnDb99B7Eqx4EL64W3rACNGOSaA72E0ju/P01fH8lJHX/DtKAbz84PrFkDQftr0Hiy6BwsM2qVUI0bZJoLcBN47oznPTB7Lp0ElufH0jhWVVzXsDkwkuehRmLIGTh+G/SbDnW5vUKoRouyTQ24hpQyNZcNNQ0nNLmf7fDeQUn27+m8RNgTv+BwHRRrfG7/9iLG8nhGgXJNDbkIn9Qnhn9nByiyu49rUNHCooa/6bBPaA338HQ2+BdS/Au1Oh9LjVaxVCtD0S6G3MqNguLLl9JKera5n22nq2HW1B+1wPb2O++lULICsF/jsWDq2xfrFCiDZFAr0NSojsxCdzR+Pr5c4Nr2/k+90tPMMedAPc/qNx4fSdK4yWATXNHJ8XQjgNCfQ2qkdQR5bfOZo+IX7c8V4y72080rI3CukPc/4HQ2YZLQPemAD5e6xbrBCiTZBAb8OCfL1YMmck4/t05bHPUnlmRQZ1dS24ecjLF658EWZ8ACVZxiyYza/LjUhCuBgJ9DbOx9Od/84cyg3Du/Hazwe464OtlFe1cOZK3GUwdwNEj4VvHoDF18oFUyFciAS6E3B3M/G3q+N59LK+rEzLZdprG8gsbOEC0n4hRtfGKf+Cw2vh1ZGQ/qV1CxZCOIQEupNQSnHb2BgW3TKMzMJypr68js2HTrb0zYwGX3esgc5RsPQm+HweVJ6ybtFCCLuSQHcy4/p05bO7xtCpgwc3vrGRJZtbsYB0cG+49QcYe7+xEtJro+HQausVK4SwKwl0JxQb7Mund45hVGwQDy/fxV8+T6W6toUrGLl7woQ/w+xvweRuTG/86o9QWWrdooUQNieB7qQ6+Xiw6OZEbrugB+9sOMLNizZTVN6KOebdR8H/rYVR8yB5Ebw6WvqsC+FkJNCdmLubiUcv78ez1w4g+XAhV768jrTs4pa/oacPTHoafr8S3L3gvavgi3vgdJH1ihZC2IwEuguYnhjFkjkjqaqp4+pX17Nk81F0a+aYdxsB/7cGxtxrtOR9aagxxi4LUwvRpkmgu4ih3QP4+p4LGNEjkIeX7+KPy3ZQ1tze6vV5dICJT8CcnyEwBj6/y+i1nr3NWiULIaxMAt2FdPH14u3Zw/nDxb35bHsWU19Zx77jrby4GTbQGIK5agEUHoGF4+GrP0B5C6dMCiFsRgLdxbiZFPde3Iv3bx1BUXkVV768jo+Sj7VuCMZkMhp93Z0MI/4PUt4xhmGS34K6Zi6bJ4SwGYsCXSk1WSm1Rym1Xyn1UAPbXKeU2q2USlNKfWDdMkVzjekZxNf3jGVAZCfmf7yTue9v5WRzV0I6l3cnuPQfxvh6177w1X1Gs6/MZOsULYRoFdXUmZtSyg3YC0wEMoEtwA1a6931tukFLAMu0loXKqW6aq3zGnvfxMREnZwsQWBrtXWaN9Yc5Lnv9uLfwYN/XpvARXEhrX9jrSH1E/juUSjNgcE3wcV/hY5BrX9vIUSDlFIpWuvE871myRn6cGC/1vqg1roK+BCYes42twOvaK0LAZoKc2E/bibFHRfG8vm8MQT5evL7t5N5ePmu1l0wBaN9QMK1MG8LjL4HdnwILw2BDa9ATaV1ihdCNIslgR4BHKv3c6b5ufp6A72VUuuUUhuVUpOtVaCwjr5h/nw+bwx3JMXw4ZajTHlxDSlHrHBh08sPLnnS6OIYMRRW/gleSoQdS2WaoxB2Zkmgq/M8d+44jTvQCxgH3AC8oZTq/Js3UmqOUipZKZWcn5/f3FpFK3m5u/HwlL58ePtIaus00xds4NmVGVTVWCF4g3vDzE9h5mfgEwCfzjH6ru/7QfquC2EnlgR6JhBV7+dIIPs823yuta7WWh8C9mAE/K9orRdqrRO11onBwcEtrVm00oiYLnx771imDYnklVUHuPrVdezJtVLvltjxcPvPMO1NqCqFxdOM/jBZKdZ5fyFEgywJ9C1AL6VUD6WUJzAD+OKcbT4DxgMopYIwhmAOWrNQYV1+3h48O30gC2cOJbe4gstfWsNz3+2hotoK0xBNJmN8/a4tcOmzkJcOr18EH94Ix9Na//5CiPNqMtC11jXAPGAlkA4s01qnKaWeUEpdad5sJXBCKbUbWAXM11qfsFXRwnou6R/K93+8kCsGhvPST/u59D9r2HDASl+duyeMmAP3bodxfzJa8742Bj6aDfl7rfMZQoizmpy2aCsybbHtWbuvgD99uoujJ8u5PjGKh6fE0dnH03ofUH4SNrwMGxdAzWlIuA7GPWi0FhBCWKSxaYsS6OJXTlfV8uJP+1i4+iABPh48cEkfpidG4WY637XxFiorgHUvwOY3oLYKBt8ISfOhczfrfYYQLkoCXTTb7uwSHvs8lZQjhfQN8+exy/syOtbKNw2V5sKaf0PKW8ZMmKE3w9gHwD/Mup8jhAuRQBctorXm6105/P2bDLKKTnNJvxD+NKUv0UEdrftBxZmw+l9Gq16TOwy6EUbPk6EYIc5DAl20SkV1LW+uPcSrq/ZTVVvHLaOjmXdRLzp18LDuBxUehjXPGXed1tVA3yuNnuwRQ6z7OUI4MQl0YRV5JRX867s9fJSSSYCPJ3+Y2JsbhkXh7mblpp2lubBpAWxZBJXFED0WxtwHPScYLQeEaMck0IVVpWYV8+RXu9l06CS9Q3x59LJ+JPW2wY1iFSWw9R3Y8CqUZkNIvHHG3v9qcLPybwdCOAkJdGF1WmtWpuXyt28yOHqynPF9gnno0r70CfWz/ofVVEHqx7DuP5CfAZ2iYNRdMHgmePla//OEaMMk0IXNVNbU8s76w7z0435OVdVw5cBw7ru4Nz2sfeEUjGZf+74zgv3oevDuDMNvh+F3gK+0khDtgwS6sLnCsioWrjnI2+sOU1Vbx7QhEdx9US+iAn1s84HHNhvBnvE1uHvBoN/BqHnQJdY2nydEGyGBLuwmv7SSV3/ez+KNR9Forh8WxdxxPYno3ME2H1iwD9a/BDuWGDcpxU6AYbdCr0ng5m6bzxTCgSTQhd3lFJ/mpZ/2m9czhasHRzB3XCwxwTYa8y7NNdY6TXnLWEHJPxISb4HBs8DPCis0CdFGSKALh8kuOs3C1QdZsvko1bV1XDYgnLvGxxIX6m+bD6ytgb3fwpY34ODPxo1KcZfBkJshZrzRCVIIJyaBLhwuv7SSN9Ye5P0NRyirquXiviHcOT6WId0CbPehBfsheZExHHP6pGkhuUwAABIVSURBVNErZsgsGHSTtBcQTksCXbQZReVVvL3+MG+tO0zx6WoGd+vMrRf0YHL/UOvfoHRGTSWkf2nMaT+0GpQb9J5knLX3vFjG2oVTkUAXbU5ZZQ0fp2Ty1rpDHD5RTngnb24eHc2M4d2s31KgvhMHjJ4x2xZDWR74hcPgm2DITOn2KJyCBLpos2rrND9l5PHm2oNsPHgSH083pg+NZPaYHtZvAvarD66GvSuMC6n7fzCei73ICPfek8HTRtMthWglCXThFFKzilm07hBf7simpk4zIS6E2WOiGR3bBWXLHi5Fx2Db+8aZe0kWePpC3yuMZfR6jJMhGdGmSKALp5JXUsH7G4/w/qajnCyrIja4IzNHdueaoZH4e9twOKauFo6sg10fwe7PoaIYfIIg/hpImA6Rw6Q5mHA4CXThlCqqa/l6Zw7vbjzCjmNF+Hi6cfXgCGaO6m67aY9n1FTCvu+NcN+7AmoqICAaBlxvPOSOVOEgEujC6e3MLOK9DUf4Ykc2lTV1DIjsxLQhkVwxMJzAjlZc9/R8KkqMWTK7lsHB/wEaIhKNYI+/BjpaeSUnIRohgS5cRmFZFcu3ZbF8ayZp2SW4mxTj47oybUgE4+O64uXuZtsCSrJh18ewcxkc32XcuBQ7wQj2PpeCdyfbfr5o9yTQhUvKyC1h+dYsPt2WRX5pJZ06eHDFwDCmDYlkUFRn215IBTieZgT7ro+hJBPcPI1w73+VMVOmQ2fbfr5olyTQhUurqa1j3YETLN+aycq0XCqq64gJ6sg1QyK4anAEkQE2noJYVwdZKZD2Kez+zJgpY/KAmHHQb6rResAn0LY1iHZDAl20G6UV1XybmssnKZlsOnQSgJExgVwzJJIpCWH4etl4CuKZcN/9GaR/AUVHjTtTe4w11kiNu1yahYlWkUAX7dKxk+V8ti2L5duyOFRQhreHicn9Q7lmSCRjegbhZrLxkIzWkLPdmAK5+3M4eRBQ0G2kMc+97xVyd6poNgl00a5prdl2rIjlWzP5ckcOxaerCfH3YuqgCKYkhDEwspPtx9u1NsbcM74yZswcTzWeD00wxtt7TYKIIWCy8UVd4fQk0IUwq6yp5af0PD7ZmsXPe/KoqdOEdfJmUv9QJvUPZVh0gO2ahNV34oAR7ntWwLGNoOuMm5h6TTQah8VeJDNmxHlJoAtxHsXl1fyYcZwVqbn8b28+lTV1BPh4MLFfCJPjQxkdG4S3hx3OmMtPwoGfjBuY9n0PFUXGdMhuo4xw7z0ZuvSUu1QFIIEuRJPKq2pYvTefFam5/JieR2llDR093Rgf15XJ8aGM69PV9hdUwVigI3ML7FsJe1dC3m7j+YAeRrj3mgjdLwAPb9vXItokCXQhmqGqpo71BwpYmXac73fnUnCqCk93E2N7BjEpPpSL+4bY/u7UM4qOGsG+dyUcXmO0IPDwMaZE9p5sPGTWTLsigS5EC9XWaVKOFLIiNZeVablkFZ3GzaRI7B7AhL5duSiuK7HBvra/qApQVQ6H1xpn73tWGDczgXFhNWac0Rmy+yjwtGHbYeFwEuhCWIHWmrTsElak5vJD+nEycksBiArswIS4EMbHdWVEj0D7jLufmTWzd4WxduqxTVBbZdzQFDUcosdC9AVGh0gZnnEpEuhC2EBW0WlWZeSxKiOPdQcKqKiuo4OHG2N6BjGhb1cu7B1MeOcO9immqhyObjDC/dBqyN1pzJxx8zon4BPB3cs+NQmbkEAXwsYqqmvZcOAEP2Xk8VNGHllFpwGICerImJ5BjOnZhVExQXTysWE/9/pOFxkBf2iNMfaeuwvQ4O5tDvgkI+AjhoK7na4HCKuQQBfCjrTW7D1+ijX78lm3v4BNh05SXlWLUpAQ0ckI+NggEqMD7DM8A8bUyLMBv9boFAng3gG6jTCfwY81bm5ys9P/dESLSKAL4UBVNXXsyCxi3f4C1u0vYNvRImrqNJ7uJhK7B5jP4INIiOhk+3YEZ5SfNFZnOhPweWnG8x4djYCPGQ89J0BwnNy92sZIoAvRhpRV1rD50EnW7S9g7f6CsxdX/b3dGRnThQt6BTE6NojY4I72mT0DUFZQL+DXQH6G8bxHRwgfbAzTdBtp/NkhwD41ifNqdaArpSYD/wHcgDe01v9oYLtrgY+AYVrrRtNaAl0IQ8GpStYfOMF6c8BnFhrj76H+3ozu2YULzGfwIf52nK1SdAyOrDc6R2ZuMS6y1tUYrwX3Nc7io0YaIR8QLXex2lGrAl0p5QbsBSYCmcAW4Aat9e5ztvMDvgY8gXkS6EK0zNET5azdX8C6AwWs319AYXk1YFxgHdo9gKHdA0iMDiAmyBeTvYZoqsqNcD+2EY5uhGNboLLYeM03BKJGGGfvkcMhbKBMlbSh1gb6KOBxrfUk888PA2it/37Odi8APwAPAA9IoAvRenV1mvTcEtbtL2DzoZOkHCk8G/CdOngwpFtnEqMDGdItgEFRnengaafx7ro6yE83h/sm48+iI8ZrJg8IG2CsuxqZaMykCYyRs3graSzQLWlOEQEcq/dzJjDinA8YDERprb9SSj3Q4kqFEL9iMin6h3eif3gn5iTForXmUEEZyUcK2XqkkOQjhazaswcAd5OiX7g/Q7oZZ/BDuwcQ1slG8+BNJgjpbzyG3Wo8V3rcGJ7J3AyZKbDtfdj8X+O1DoHmcE+EyKFGyMtYvNVZEujn+9/q2dN6pZQJeB64pck3UmoOMAegWzdp7C9EcymliAn2JSbYl+sSowAoKq9i29Eiko8YZ/AfbjnK2+sPAxDeyZuh0YEM7daZod0D6RvmZ7v2wH4h0Pdy4wFGo7H8DCPks5KNkN/3PWfjo0tP407WiKHGdMmQeLnpqZVaPeSilOoEHABOmXcJBU4CVzY27CJDLkLYRnVtHek5JaQcKTz7yCmuAKCDhxuDojobY/HRAQyJCrDfzU4AFSWQvRUyk3+54FqWb7zm5mn0pYkcDlHDIGyQ0WXSZIf+9E6ktWPo7hgXRScAWRgXRX+ntU5rYPufkTF0IdqU7KLTvwr43Tkl1NYZ/+33DvFlaPcAhnQzhml6BNlxuqTWUJxphHtWihH02dugxpjpg6evEeyRieaz+SHgF9aux+OtMW1xCvACxrTFRVrrp5VSTwDJWusvztn2ZyTQhWjTyqtq2H6siK31Qr6kwpiWGNjRk8FRnRkQ2ZmBUZ0YGNmZAHu1CwaorTYaj+XuMqZLZqVAzk6oMy4G4xNknMmHDYDQAcbfu/RsNzdAyY1FQohG1dVpDuSfIsV8oXX7sSIO5J/iTDx0C/RhQKQR7gOjOhMf4Y+Ppx0W/Dij+jTk7DAeuTuNgM9L/yXk3TsYF2jDBxtn8pGJLjuzRgJdCNFspRXV7MoqZmdmMTuOFbEzs/hs0zGTgl5d/UiI7ET/cH/6hfnTN9wff287jsfXVEHB3l/O5HN2Qs52qDJfzqs/syakP3Tta9wE5eRn8hLoQgiryC+tZGdmETvMIZ+aVcyJsqqzr3cL9KFfmL8R8uH+9A/vRIi/l/3G5Otqf5lZk5lsPPIzODuzxt0bgvtASAKED3LK2TUS6EIIm9Bak1daye7sEnbnlJCWXczu7BIOnyg/u01gR89zQt6fHkG+9mtEVnkK8vcY67PmZ5jH53dC+QnjdZMHhPSDruaz+DMP/4g2OWQjgS6EsKtTlTWk55QYQZ9dQlpOMXtzT1FVWweAt4eJPqH+Z4dr+oX70zfU3353umoNxccga6sxqyZnO+RlwKncX7bx8q8X8P2MzpNd+4FvsH1qbIAEuhDC4apr69ifd+o3Z/NnZteYFPQI6kj/8E70Mwd9/3B/uvjacTik/KRxsTU/3fgzL904sz9d+Ms2PkEQGm8M1ZyZZRPUy2595CXQhRBtktaarKLTpJ05k88uIT2n5OzFV4AQfy9zuP8S9FGBPvYbstEaTh2vF/BpkJtq/L220tjGzQu6xhnhHjrAHPbx4N3J6uVIoAshnEpRedXZM/kzQb8//9TZm6G8PUz0DvGjT4gffULNjxA/gv3seAG2tgZO7DPPsqn3KC/4ZZvO3c0hn2DMtAk2z7Rxa/mUTwl0IYTTq6iuZd/xU+zOKWZP7in2HC9hT+4pCk5Vnt0mwMfjbLj3CfWnT6gvvUP88LPXdEqtoTQXjqcaF15zdxln8yf2c3amjZsndOllnNEHxxmzboL7QmAPi4ZtJNCFEC7rxKlK9uSWsud46dk/9+aWUlZVe3abiM4d6BPqR+8QP+JC/egV4ktMkK/9LsJWlRkzbPL3mMfo9xg/n2k5DMZsmy49zxP0Mb9ayLu17XOFEKLN6uLrxeieXozuGXT2ubo6Y2w+I7eUvWeCPreU1XvzqTEP2yhlBH1ssC+xwb707OpLbHBHenb1JbCjp3WHbjw7mrtKDv3181Vlxs1R9YM+ezukfcbZM3qTOwTG/hL0jZBAF0K4HJNJERXoQ1SgDxP7hZx9vqqmjkMFZezPO8X+vFMcyDcemw6doKK67ux2nX086GkO+tiuHc1h70tkgJUvxnqa12wNH/zr56vKjfH5+kGfmwrpXzb6djLkIoRo9+rqNNnFp80hX3Y27A/mn6Lg1C93wnq6m4gJ6mgO+l/O6O02fFN9GuXpI0MuQgjREJNJERngQ2SAD+P6/Pq1wrIqDhacOhv2B/JOkZpdzLepOZhHb+w3fOPR+ApUEuhCCNGIgI6eDO0YyNDugb96vqK6lsMnyjiQV9Y2hm+QQBdCiBbx9nAjLtSfuFD/Xz3f0PDNjxnHWZps2+EbCXQhhLAiWw/fNEYCXQgh7MQawzeNkUAXQggHa87wzY5G3kcCXQgh2qjzDd/8o7Ht7VKVEEIIm5NAF0IIFyGBLoQQLkICXQghXIQEuhBCuAgJdCGEcBES6EII4SIk0IUQwkU4rB+6UqoU2OOQD7ePIKCgya2clxyfc5Pjc17dtdbB53vBkXeK7mmoSbsrUEoly/E5Lzk+5+bqx9cQGXIRQggXIYEuhBAuwpGBvtCBn20PcnzOTY7Pubn68Z2Xwy6KCiGEsC4ZchFCCBfhkEBXSk1WSu1RSu1XSj3kiBqsTSl1WCm1Sym1XSmVbH4uUCn1vVJqn/nPAEfXaSml1CKlVJ5SKrXec+c9HmV40fx97lRKDXFc5ZZp4PgeV0plmb/D7UqpKfVee9h8fHuUUpMcU7VllFJRSqlVSql0pVSaUupe8/Mu8f01cnwu8f21itbarg/ADTgAxACewA6gn73rsMFxHQaCznnun8BD5r8/BDzj6DqbcTxJwBAgtanjAaYA3wIKGAlscnT9LTy+x4EHzrNtP/O/p15AD/O/v26OPoZGji0MGGL+ux+w13wMLvH9NXJ8LvH9tebhiDP04cB+rfVBrXUV8CEw1QF12MNU4B3z398BrnJgLc2itV4NnDzn6YaOZyrwrjZsBDorpcLsU2nLNHB8DZkKfKi1rtRaHwL2Y/x73CZprXO01lvNfy8F0oEIXOT7a+T4GuJU319rOCLQI4Bj9X7OpPEvw1lo4DulVIpSao75uRCtdQ4Y/xICXR1WnXU0dDyu9J3OMw87LKo3ROa0x6eUigYGA5twwe/vnOMDF/v+mssRga7O85wrTLUZo7UeAlwK3KWUSnJ0QXbkKt/pa0AsMAjIAZ4zP++Ux6eU8gU+Ae7TWpc0tul5nnPG43Op768lHBHomUBUvZ8jgWwH1GFVWuts8595wKcYv9IdP/Orq/nPPMdVaBUNHY9LfKda6+Na61qtdR3wOr/8Wu50x6eU8sAIu8Va6+Xmp13m+zvf8bnS99dSjgj0LUAvpVQPpZQnMAP4wgF1WI1SqqNSyu/M34FLgFSM47rZvNnNwOeOqdBqGjqeL4BZ5tkSI4HiM7/aO5Nzxo2vxvgOwTi+GUopL6VUD6AXsNne9VlKKaWAN4F0rfW/673kEt9fQ8fnKt9fqzjiSizGVfW9GFebH3H0lWErHE8MxlX0HUDamWMCugA/AvvMfwY6utZmHNMSjF9bqzHOcG5t6HgwfqV9xfx97gISHV1/C4/vPXP9OzFCIKze9o+Yj28PcKmj62/i2C7AGFLYCWw3P6a4yvfXyPG5xPfXmofcKSqEEC5C7hQVQggXIYEuhBAuQgJdCCFchAS6EEK4CAl0IYRwERLoQgjhIiTQhRDCRUigCyGEi/j/tiESmLPCSLIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4fcb48ef50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.33074381947517395, 0.96666664]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### when deploying you can then retrain on the whole data i.e. not train_test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/300\n",
      "150/150 [==============================] - 1s 5ms/sample - loss: 1.0983 - accuracy: 0.3333\n",
      "Epoch 2/300\n",
      "150/150 [==============================] - 0s 244us/sample - loss: 1.0912 - accuracy: 0.3333\n",
      "Epoch 3/300\n",
      "150/150 [==============================] - 0s 216us/sample - loss: 1.0843 - accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "150/150 [==============================] - 0s 244us/sample - loss: 1.0786 - accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "150/150 [==============================] - 0s 228us/sample - loss: 1.0726 - accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "150/150 [==============================] - 0s 205us/sample - loss: 1.0669 - accuracy: 0.3400\n",
      "Epoch 7/300\n",
      "150/150 [==============================] - 0s 190us/sample - loss: 1.0617 - accuracy: 0.3467\n",
      "Epoch 8/300\n",
      "150/150 [==============================] - 0s 185us/sample - loss: 1.0569 - accuracy: 0.3533\n",
      "Epoch 9/300\n",
      "150/150 [==============================] - 0s 198us/sample - loss: 1.0517 - accuracy: 0.3600\n",
      "Epoch 10/300\n",
      "150/150 [==============================] - 0s 136us/sample - loss: 1.0470 - accuracy: 0.3667\n",
      "Epoch 11/300\n",
      "150/150 [==============================] - 0s 226us/sample - loss: 1.0425 - accuracy: 0.3733\n",
      "Epoch 12/300\n",
      "150/150 [==============================] - 0s 169us/sample - loss: 1.0384 - accuracy: 0.3933\n",
      "Epoch 13/300\n",
      "150/150 [==============================] - 0s 241us/sample - loss: 1.0344 - accuracy: 0.3933\n",
      "Epoch 14/300\n",
      "150/150 [==============================] - 0s 242us/sample - loss: 1.0304 - accuracy: 0.4133\n",
      "Epoch 15/300\n",
      "150/150 [==============================] - 0s 232us/sample - loss: 1.0266 - accuracy: 0.4133\n",
      "Epoch 16/300\n",
      "150/150 [==============================] - 0s 429us/sample - loss: 1.0231 - accuracy: 0.4200\n",
      "Epoch 17/300\n",
      "150/150 [==============================] - 0s 220us/sample - loss: 1.0196 - accuracy: 0.4267\n",
      "Epoch 18/300\n",
      "150/150 [==============================] - 0s 270us/sample - loss: 1.0162 - accuracy: 0.4533\n",
      "Epoch 19/300\n",
      "150/150 [==============================] - 0s 578us/sample - loss: 1.0129 - accuracy: 0.4467\n",
      "Epoch 20/300\n",
      "150/150 [==============================] - 0s 270us/sample - loss: 1.0096 - accuracy: 0.4533\n",
      "Epoch 21/300\n",
      "150/150 [==============================] - 0s 328us/sample - loss: 1.0063 - accuracy: 0.4533\n",
      "Epoch 22/300\n",
      "150/150 [==============================] - 0s 306us/sample - loss: 1.0030 - accuracy: 0.4467\n",
      "Epoch 23/300\n",
      "150/150 [==============================] - 0s 769us/sample - loss: 0.9996 - accuracy: 0.4667\n",
      "Epoch 24/300\n",
      "150/150 [==============================] - 0s 492us/sample - loss: 0.9962 - accuracy: 0.4733\n",
      "Epoch 25/300\n",
      "150/150 [==============================] - 0s 318us/sample - loss: 0.9928 - accuracy: 0.5000\n",
      "Epoch 26/300\n",
      "150/150 [==============================] - 0s 398us/sample - loss: 0.9894 - accuracy: 0.5000\n",
      "Epoch 27/300\n",
      "150/150 [==============================] - 0s 498us/sample - loss: 0.9860 - accuracy: 0.5067\n",
      "Epoch 28/300\n",
      "150/150 [==============================] - 0s 598us/sample - loss: 0.9826 - accuracy: 0.5200\n",
      "Epoch 29/300\n",
      "150/150 [==============================] - 0s 332us/sample - loss: 0.9793 - accuracy: 0.5333\n",
      "Epoch 30/300\n",
      "150/150 [==============================] - 0s 325us/sample - loss: 0.9759 - accuracy: 0.5467\n",
      "Epoch 31/300\n",
      "150/150 [==============================] - 0s 739us/sample - loss: 0.9726 - accuracy: 0.5467\n",
      "Epoch 32/300\n",
      "150/150 [==============================] - 0s 365us/sample - loss: 0.9692 - accuracy: 0.5467\n",
      "Epoch 33/300\n",
      "150/150 [==============================] - 0s 436us/sample - loss: 0.9658 - accuracy: 0.5533\n",
      "Epoch 34/300\n",
      "150/150 [==============================] - 0s 192us/sample - loss: 0.9625 - accuracy: 0.5533\n",
      "Epoch 35/300\n",
      "150/150 [==============================] - 0s 241us/sample - loss: 0.9590 - accuracy: 0.5533\n",
      "Epoch 36/300\n",
      "150/150 [==============================] - 0s 442us/sample - loss: 0.9555 - accuracy: 0.5533\n",
      "Epoch 37/300\n",
      "150/150 [==============================] - 0s 203us/sample - loss: 0.9520 - accuracy: 0.5467\n",
      "Epoch 38/300\n",
      "150/150 [==============================] - 0s 254us/sample - loss: 0.9485 - accuracy: 0.5533\n",
      "Epoch 39/300\n",
      "150/150 [==============================] - 0s 206us/sample - loss: 0.9450 - accuracy: 0.5533\n",
      "Epoch 40/300\n",
      "150/150 [==============================] - 0s 193us/sample - loss: 0.9414 - accuracy: 0.5533\n",
      "Epoch 41/300\n",
      "150/150 [==============================] - 0s 173us/sample - loss: 0.9379 - accuracy: 0.5533\n",
      "Epoch 42/300\n",
      "150/150 [==============================] - 0s 173us/sample - loss: 0.9345 - accuracy: 0.5600\n",
      "Epoch 43/300\n",
      "150/150 [==============================] - 0s 244us/sample - loss: 0.9310 - accuracy: 0.5600\n",
      "Epoch 44/300\n",
      "150/150 [==============================] - 0s 199us/sample - loss: 0.9274 - accuracy: 0.5733\n",
      "Epoch 45/300\n",
      "150/150 [==============================] - 0s 212us/sample - loss: 0.9239 - accuracy: 0.5800\n",
      "Epoch 46/300\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.9203 - accuracy: 0.5667\n",
      "Epoch 47/300\n",
      "150/150 [==============================] - 0s 211us/sample - loss: 0.9168 - accuracy: 0.5733\n",
      "Epoch 48/300\n",
      "150/150 [==============================] - 0s 194us/sample - loss: 0.9131 - accuracy: 0.5733\n",
      "Epoch 49/300\n",
      "150/150 [==============================] - 0s 248us/sample - loss: 0.9095 - accuracy: 0.6467\n",
      "Epoch 50/300\n",
      "150/150 [==============================] - 0s 185us/sample - loss: 0.9059 - accuracy: 0.6533\n",
      "Epoch 51/300\n",
      "150/150 [==============================] - 0s 183us/sample - loss: 0.9023 - accuracy: 0.6533\n",
      "Epoch 52/300\n",
      "150/150 [==============================] - 0s 201us/sample - loss: 0.8987 - accuracy: 0.6600\n",
      "Epoch 53/300\n",
      "150/150 [==============================] - 0s 358us/sample - loss: 0.8951 - accuracy: 0.6600\n",
      "Epoch 54/300\n",
      "150/150 [==============================] - 0s 240us/sample - loss: 0.8916 - accuracy: 0.6600\n",
      "Epoch 55/300\n",
      "150/150 [==============================] - 0s 186us/sample - loss: 0.8879 - accuracy: 0.6600\n",
      "Epoch 56/300\n",
      "150/150 [==============================] - 0s 161us/sample - loss: 0.8844 - accuracy: 0.6600\n",
      "Epoch 57/300\n",
      "150/150 [==============================] - 0s 323us/sample - loss: 0.8806 - accuracy: 0.6667\n",
      "Epoch 58/300\n",
      "150/150 [==============================] - 0s 182us/sample - loss: 0.8772 - accuracy: 0.6800\n",
      "Epoch 59/300\n",
      "150/150 [==============================] - 0s 327us/sample - loss: 0.8736 - accuracy: 0.6800\n",
      "Epoch 60/300\n",
      "150/150 [==============================] - 0s 425us/sample - loss: 0.8701 - accuracy: 0.6800\n",
      "Epoch 61/300\n",
      "150/150 [==============================] - 0s 232us/sample - loss: 0.8665 - accuracy: 0.6800\n",
      "Epoch 62/300\n",
      "150/150 [==============================] - 0s 215us/sample - loss: 0.8629 - accuracy: 0.6867\n",
      "Epoch 63/300\n",
      "150/150 [==============================] - 0s 284us/sample - loss: 0.8595 - accuracy: 0.6867\n",
      "Epoch 64/300\n",
      "150/150 [==============================] - 0s 207us/sample - loss: 0.8559 - accuracy: 0.6867\n",
      "Epoch 65/300\n",
      "150/150 [==============================] - 0s 182us/sample - loss: 0.8525 - accuracy: 0.6933\n",
      "Epoch 66/300\n",
      "150/150 [==============================] - 0s 178us/sample - loss: 0.8488 - accuracy: 0.7000\n",
      "Epoch 67/300\n",
      "150/150 [==============================] - 0s 324us/sample - loss: 0.8454 - accuracy: 0.7000\n",
      "Epoch 68/300\n",
      "150/150 [==============================] - 0s 175us/sample - loss: 0.8419 - accuracy: 0.7000\n",
      "Epoch 69/300\n",
      "150/150 [==============================] - 0s 286us/sample - loss: 0.8384 - accuracy: 0.7067\n",
      "Epoch 70/300\n",
      "150/150 [==============================] - 0s 348us/sample - loss: 0.8351 - accuracy: 0.7067\n",
      "Epoch 71/300\n",
      "150/150 [==============================] - 0s 166us/sample - loss: 0.8316 - accuracy: 0.7067\n",
      "Epoch 72/300\n",
      "150/150 [==============================] - 0s 186us/sample - loss: 0.8281 - accuracy: 0.7067\n",
      "Epoch 73/300\n",
      "150/150 [==============================] - 0s 201us/sample - loss: 0.8247 - accuracy: 0.7133\n",
      "Epoch 74/300\n",
      "150/150 [==============================] - 0s 241us/sample - loss: 0.8214 - accuracy: 0.7200\n",
      "Epoch 75/300\n",
      "150/150 [==============================] - 0s 199us/sample - loss: 0.8181 - accuracy: 0.7267\n",
      "Epoch 76/300\n",
      "150/150 [==============================] - 0s 196us/sample - loss: 0.8146 - accuracy: 0.7333\n",
      "Epoch 77/300\n",
      "150/150 [==============================] - 0s 189us/sample - loss: 0.8114 - accuracy: 0.7400\n",
      "Epoch 78/300\n",
      "150/150 [==============================] - 0s 179us/sample - loss: 0.8080 - accuracy: 0.7533\n",
      "Epoch 79/300\n",
      "150/150 [==============================] - 0s 262us/sample - loss: 0.8048 - accuracy: 0.7533\n",
      "Epoch 80/300\n",
      "150/150 [==============================] - 0s 461us/sample - loss: 0.8015 - accuracy: 0.7533\n",
      "Epoch 81/300\n",
      "150/150 [==============================] - 0s 278us/sample - loss: 0.7982 - accuracy: 0.7533\n",
      "Epoch 82/300\n",
      "150/150 [==============================] - 0s 214us/sample - loss: 0.7951 - accuracy: 0.7533\n",
      "Epoch 83/300\n",
      "150/150 [==============================] - 0s 477us/sample - loss: 0.7919 - accuracy: 0.7600\n",
      "Epoch 84/300\n",
      "150/150 [==============================] - 0s 355us/sample - loss: 0.7886 - accuracy: 0.7667\n",
      "Epoch 85/300\n",
      "150/150 [==============================] - 0s 429us/sample - loss: 0.7855 - accuracy: 0.7733\n",
      "Epoch 86/300\n",
      "150/150 [==============================] - 0s 511us/sample - loss: 0.7824 - accuracy: 0.7733\n",
      "Epoch 87/300\n",
      "150/150 [==============================] - 0s 302us/sample - loss: 0.7793 - accuracy: 0.7733\n",
      "Epoch 88/300\n",
      "150/150 [==============================] - 0s 226us/sample - loss: 0.7763 - accuracy: 0.7733\n",
      "Epoch 89/300\n",
      "150/150 [==============================] - 0s 314us/sample - loss: 0.7732 - accuracy: 0.7800\n",
      "Epoch 90/300\n",
      "150/150 [==============================] - 0s 628us/sample - loss: 0.7702 - accuracy: 0.7933\n",
      "Epoch 91/300\n",
      "150/150 [==============================] - 0s 418us/sample - loss: 0.7672 - accuracy: 0.7933\n",
      "Epoch 92/300\n",
      "150/150 [==============================] - 0s 174us/sample - loss: 0.7642 - accuracy: 0.8067\n",
      "Epoch 93/300\n",
      "150/150 [==============================] - 0s 293us/sample - loss: 0.7612 - accuracy: 0.8067\n",
      "Epoch 94/300\n",
      "150/150 [==============================] - 0s 211us/sample - loss: 0.7583 - accuracy: 0.8067\n",
      "Epoch 95/300\n",
      "150/150 [==============================] - 0s 213us/sample - loss: 0.7554 - accuracy: 0.8067\n",
      "Epoch 96/300\n",
      "150/150 [==============================] - 0s 264us/sample - loss: 0.7525 - accuracy: 0.8067\n",
      "Epoch 97/300\n",
      "150/150 [==============================] - 0s 215us/sample - loss: 0.7497 - accuracy: 0.8067\n",
      "Epoch 98/300\n",
      "150/150 [==============================] - 0s 265us/sample - loss: 0.7468 - accuracy: 0.8000\n",
      "Epoch 99/300\n",
      "150/150 [==============================] - 0s 189us/sample - loss: 0.7441 - accuracy: 0.8000\n",
      "Epoch 100/300\n",
      "150/150 [==============================] - 0s 275us/sample - loss: 0.7413 - accuracy: 0.8000\n",
      "Epoch 101/300\n",
      "150/150 [==============================] - 0s 289us/sample - loss: 0.7386 - accuracy: 0.8000\n",
      "Epoch 102/300\n",
      "150/150 [==============================] - 0s 213us/sample - loss: 0.7358 - accuracy: 0.8000\n",
      "Epoch 103/300\n",
      "150/150 [==============================] - 0s 220us/sample - loss: 0.7332 - accuracy: 0.8067\n",
      "Epoch 104/300\n",
      "150/150 [==============================] - 0s 266us/sample - loss: 0.7306 - accuracy: 0.8067\n",
      "Epoch 105/300\n",
      "150/150 [==============================] - 0s 256us/sample - loss: 0.7279 - accuracy: 0.8133\n",
      "Epoch 106/300\n",
      "150/150 [==============================] - 0s 211us/sample - loss: 0.7253 - accuracy: 0.8133\n",
      "Epoch 107/300\n",
      "150/150 [==============================] - 0s 338us/sample - loss: 0.7227 - accuracy: 0.8133\n",
      "Epoch 108/300\n",
      "150/150 [==============================] - 0s 334us/sample - loss: 0.7202 - accuracy: 0.8200\n",
      "Epoch 109/300\n",
      "150/150 [==============================] - 0s 377us/sample - loss: 0.7177 - accuracy: 0.8200\n",
      "Epoch 110/300\n",
      "150/150 [==============================] - 0s 247us/sample - loss: 0.7152 - accuracy: 0.8267\n",
      "Epoch 111/300\n",
      "150/150 [==============================] - 0s 368us/sample - loss: 0.7127 - accuracy: 0.8267\n",
      "Epoch 112/300\n",
      "150/150 [==============================] - 0s 246us/sample - loss: 0.7103 - accuracy: 0.8267\n",
      "Epoch 113/300\n",
      "150/150 [==============================] - 0s 277us/sample - loss: 0.7078 - accuracy: 0.8267\n",
      "Epoch 114/300\n",
      "150/150 [==============================] - 0s 298us/sample - loss: 0.7054 - accuracy: 0.8267\n",
      "Epoch 115/300\n",
      "150/150 [==============================] - 0s 186us/sample - loss: 0.7031 - accuracy: 0.8400\n",
      "Epoch 116/300\n",
      "150/150 [==============================] - 0s 176us/sample - loss: 0.7007 - accuracy: 0.8400\n",
      "Epoch 117/300\n",
      "150/150 [==============================] - 0s 182us/sample - loss: 0.6984 - accuracy: 0.8400\n",
      "Epoch 118/300\n",
      "150/150 [==============================] - 0s 198us/sample - loss: 0.6961 - accuracy: 0.8467\n",
      "Epoch 119/300\n",
      "150/150 [==============================] - 0s 191us/sample - loss: 0.6938 - accuracy: 0.8467\n",
      "Epoch 120/300\n",
      "150/150 [==============================] - 0s 219us/sample - loss: 0.6916 - accuracy: 0.8467\n",
      "Epoch 121/300\n",
      "150/150 [==============================] - 0s 220us/sample - loss: 0.6893 - accuracy: 0.8467\n",
      "Epoch 122/300\n",
      "150/150 [==============================] - 0s 185us/sample - loss: 0.6871 - accuracy: 0.8467\n",
      "Epoch 123/300\n",
      "150/150 [==============================] - 0s 212us/sample - loss: 0.6849 - accuracy: 0.8600\n",
      "Epoch 124/300\n",
      "150/150 [==============================] - 0s 209us/sample - loss: 0.6827 - accuracy: 0.8667\n",
      "Epoch 125/300\n",
      "150/150 [==============================] - 0s 280us/sample - loss: 0.6806 - accuracy: 0.8667\n",
      "Epoch 126/300\n",
      "150/150 [==============================] - 0s 198us/sample - loss: 0.6784 - accuracy: 0.8667\n",
      "Epoch 127/300\n",
      "150/150 [==============================] - 0s 276us/sample - loss: 0.6763 - accuracy: 0.8733\n",
      "Epoch 128/300\n",
      "150/150 [==============================] - 0s 241us/sample - loss: 0.6742 - accuracy: 0.8800\n",
      "Epoch 129/300\n",
      "150/150 [==============================] - 0s 411us/sample - loss: 0.6722 - accuracy: 0.8733\n",
      "Epoch 130/300\n",
      "150/150 [==============================] - 0s 265us/sample - loss: 0.6700 - accuracy: 0.8800\n",
      "Epoch 131/300\n",
      "150/150 [==============================] - 0s 270us/sample - loss: 0.6680 - accuracy: 0.8800\n",
      "Epoch 132/300\n",
      "150/150 [==============================] - 0s 159us/sample - loss: 0.6658 - accuracy: 0.8867\n",
      "Epoch 133/300\n",
      "150/150 [==============================] - 0s 129us/sample - loss: 0.6636 - accuracy: 0.8933\n",
      "Epoch 134/300\n",
      "150/150 [==============================] - 0s 210us/sample - loss: 0.6615 - accuracy: 0.9000\n",
      "Epoch 135/300\n",
      "150/150 [==============================] - 0s 138us/sample - loss: 0.6595 - accuracy: 0.9000\n",
      "Epoch 136/300\n",
      "150/150 [==============================] - 0s 254us/sample - loss: 0.6574 - accuracy: 0.9000\n",
      "Epoch 137/300\n",
      "150/150 [==============================] - 0s 372us/sample - loss: 0.6553 - accuracy: 0.8867\n",
      "Epoch 138/300\n",
      "150/150 [==============================] - 0s 185us/sample - loss: 0.6530 - accuracy: 0.8933\n",
      "Epoch 139/300\n",
      "150/150 [==============================] - 0s 222us/sample - loss: 0.6507 - accuracy: 0.8933\n",
      "Epoch 140/300\n",
      "150/150 [==============================] - 0s 266us/sample - loss: 0.6486 - accuracy: 0.9000\n",
      "Epoch 141/300\n",
      "150/150 [==============================] - 0s 236us/sample - loss: 0.6462 - accuracy: 0.9067\n",
      "Epoch 142/300\n",
      "150/150 [==============================] - 0s 195us/sample - loss: 0.6440 - accuracy: 0.8933\n",
      "Epoch 143/300\n",
      "150/150 [==============================] - 0s 221us/sample - loss: 0.6416 - accuracy: 0.9067\n",
      "Epoch 144/300\n",
      "150/150 [==============================] - 0s 332us/sample - loss: 0.6391 - accuracy: 0.9067\n",
      "Epoch 145/300\n",
      "150/150 [==============================] - 0s 265us/sample - loss: 0.6368 - accuracy: 0.8867\n",
      "Epoch 146/300\n",
      "150/150 [==============================] - 0s 313us/sample - loss: 0.6339 - accuracy: 0.8667\n",
      "Epoch 147/300\n",
      "150/150 [==============================] - 0s 232us/sample - loss: 0.6309 - accuracy: 0.8467\n",
      "Epoch 148/300\n",
      "150/150 [==============================] - 0s 250us/sample - loss: 0.6283 - accuracy: 0.7933\n",
      "Epoch 149/300\n",
      "150/150 [==============================] - 0s 204us/sample - loss: 0.6258 - accuracy: 0.7800\n",
      "Epoch 150/300\n",
      "150/150 [==============================] - 0s 206us/sample - loss: 0.6232 - accuracy: 0.7600\n",
      "Epoch 151/300\n",
      "150/150 [==============================] - 0s 179us/sample - loss: 0.6203 - accuracy: 0.7467\n",
      "Epoch 152/300\n",
      "150/150 [==============================] - 0s 202us/sample - loss: 0.6179 - accuracy: 0.7467\n",
      "Epoch 153/300\n",
      "150/150 [==============================] - 0s 251us/sample - loss: 0.6156 - accuracy: 0.7533\n",
      "Epoch 154/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 246us/sample - loss: 0.6131 - accuracy: 0.7467\n",
      "Epoch 155/300\n",
      "150/150 [==============================] - 0s 168us/sample - loss: 0.6108 - accuracy: 0.7533\n",
      "Epoch 156/300\n",
      "150/150 [==============================] - 0s 155us/sample - loss: 0.6085 - accuracy: 0.7533\n",
      "Epoch 157/300\n",
      "150/150 [==============================] - 0s 199us/sample - loss: 0.6062 - accuracy: 0.7533\n",
      "Epoch 158/300\n",
      "150/150 [==============================] - 0s 208us/sample - loss: 0.6040 - accuracy: 0.7533\n",
      "Epoch 159/300\n",
      "150/150 [==============================] - 0s 218us/sample - loss: 0.6019 - accuracy: 0.7533\n",
      "Epoch 160/300\n",
      "150/150 [==============================] - 0s 192us/sample - loss: 0.5997 - accuracy: 0.7533\n",
      "Epoch 161/300\n",
      "150/150 [==============================] - 0s 214us/sample - loss: 0.5975 - accuracy: 0.7533\n",
      "Epoch 162/300\n",
      "150/150 [==============================] - 0s 195us/sample - loss: 0.5953 - accuracy: 0.7533\n",
      "Epoch 163/300\n",
      "150/150 [==============================] - 0s 225us/sample - loss: 0.5932 - accuracy: 0.7533\n",
      "Epoch 164/300\n",
      "150/150 [==============================] - 0s 239us/sample - loss: 0.5911 - accuracy: 0.7467\n",
      "Epoch 165/300\n",
      "150/150 [==============================] - 0s 283us/sample - loss: 0.5891 - accuracy: 0.7467\n",
      "Epoch 166/300\n",
      "150/150 [==============================] - 0s 240us/sample - loss: 0.5872 - accuracy: 0.7533\n",
      "Epoch 167/300\n",
      "150/150 [==============================] - 0s 307us/sample - loss: 0.5853 - accuracy: 0.7533\n",
      "Epoch 168/300\n",
      "150/150 [==============================] - 0s 188us/sample - loss: 0.5833 - accuracy: 0.7533\n",
      "Epoch 169/300\n",
      "150/150 [==============================] - 0s 296us/sample - loss: 0.5814 - accuracy: 0.7533\n",
      "Epoch 170/300\n",
      "150/150 [==============================] - 0s 157us/sample - loss: 0.5796 - accuracy: 0.7533\n",
      "Epoch 171/300\n",
      "150/150 [==============================] - 0s 215us/sample - loss: 0.5777 - accuracy: 0.7533\n",
      "Epoch 172/300\n",
      "150/150 [==============================] - 0s 192us/sample - loss: 0.5758 - accuracy: 0.7533\n",
      "Epoch 173/300\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.5740 - accuracy: 0.7533\n",
      "Epoch 174/300\n",
      "150/150 [==============================] - 0s 186us/sample - loss: 0.5722 - accuracy: 0.7533\n",
      "Epoch 175/300\n",
      "150/150 [==============================] - 0s 144us/sample - loss: 0.5705 - accuracy: 0.7533\n",
      "Epoch 176/300\n",
      "150/150 [==============================] - 0s 191us/sample - loss: 0.5687 - accuracy: 0.7533\n",
      "Epoch 177/300\n",
      "150/150 [==============================] - 0s 190us/sample - loss: 0.5669 - accuracy: 0.7533\n",
      "Epoch 178/300\n",
      "150/150 [==============================] - 0s 229us/sample - loss: 0.5651 - accuracy: 0.7533\n",
      "Epoch 179/300\n",
      "150/150 [==============================] - 0s 220us/sample - loss: 0.5636 - accuracy: 0.7533\n",
      "Epoch 180/300\n",
      "150/150 [==============================] - 0s 263us/sample - loss: 0.5617 - accuracy: 0.7533\n",
      "Epoch 181/300\n",
      "150/150 [==============================] - 0s 261us/sample - loss: 0.5600 - accuracy: 0.7533\n",
      "Epoch 182/300\n",
      "150/150 [==============================] - 0s 379us/sample - loss: 0.5585 - accuracy: 0.7533\n",
      "Epoch 183/300\n",
      "150/150 [==============================] - 0s 241us/sample - loss: 0.5568 - accuracy: 0.7533\n",
      "Epoch 184/300\n",
      "150/150 [==============================] - 0s 163us/sample - loss: 0.5550 - accuracy: 0.7533\n",
      "Epoch 185/300\n",
      "150/150 [==============================] - 0s 160us/sample - loss: 0.5534 - accuracy: 0.7533\n",
      "Epoch 186/300\n",
      "150/150 [==============================] - 0s 129us/sample - loss: 0.5517 - accuracy: 0.7533\n",
      "Epoch 187/300\n",
      "150/150 [==============================] - 0s 158us/sample - loss: 0.5501 - accuracy: 0.7533\n",
      "Epoch 188/300\n",
      "150/150 [==============================] - 0s 193us/sample - loss: 0.5486 - accuracy: 0.7533\n",
      "Epoch 189/300\n",
      "150/150 [==============================] - 0s 182us/sample - loss: 0.5473 - accuracy: 0.7533\n",
      "Epoch 190/300\n",
      "150/150 [==============================] - 0s 178us/sample - loss: 0.5453 - accuracy: 0.7533\n",
      "Epoch 191/300\n",
      "150/150 [==============================] - 0s 247us/sample - loss: 0.5438 - accuracy: 0.7533\n",
      "Epoch 192/300\n",
      "150/150 [==============================] - 0s 215us/sample - loss: 0.5423 - accuracy: 0.7533\n",
      "Epoch 193/300\n",
      "150/150 [==============================] - 0s 186us/sample - loss: 0.5409 - accuracy: 0.7600\n",
      "Epoch 194/300\n",
      "150/150 [==============================] - 0s 185us/sample - loss: 0.5392 - accuracy: 0.7667\n",
      "Epoch 195/300\n",
      "150/150 [==============================] - 0s 191us/sample - loss: 0.5377 - accuracy: 0.7600\n",
      "Epoch 196/300\n",
      "150/150 [==============================] - 0s 173us/sample - loss: 0.5361 - accuracy: 0.7600\n",
      "Epoch 197/300\n",
      "150/150 [==============================] - 0s 181us/sample - loss: 0.5348 - accuracy: 0.7533\n",
      "Epoch 198/300\n",
      "150/150 [==============================] - 0s 239us/sample - loss: 0.5331 - accuracy: 0.7533\n",
      "Epoch 199/300\n",
      "150/150 [==============================] - 0s 221us/sample - loss: 0.5316 - accuracy: 0.7600\n",
      "Epoch 200/300\n",
      "150/150 [==============================] - 0s 185us/sample - loss: 0.5301 - accuracy: 0.7600\n",
      "Epoch 201/300\n",
      "150/150 [==============================] - 0s 195us/sample - loss: 0.5287 - accuracy: 0.7600\n",
      "Epoch 202/300\n",
      "150/150 [==============================] - 0s 548us/sample - loss: 0.5272 - accuracy: 0.7600\n",
      "Epoch 203/300\n",
      "150/150 [==============================] - 0s 222us/sample - loss: 0.5259 - accuracy: 0.7600\n",
      "Epoch 204/300\n",
      "150/150 [==============================] - 0s 202us/sample - loss: 0.5243 - accuracy: 0.7667\n",
      "Epoch 205/300\n",
      "150/150 [==============================] - 0s 253us/sample - loss: 0.5229 - accuracy: 0.7867\n",
      "Epoch 206/300\n",
      "150/150 [==============================] - 0s 176us/sample - loss: 0.5215 - accuracy: 0.7933\n",
      "Epoch 207/300\n",
      "150/150 [==============================] - 0s 223us/sample - loss: 0.5201 - accuracy: 0.7933\n",
      "Epoch 208/300\n",
      "150/150 [==============================] - 0s 437us/sample - loss: 0.5187 - accuracy: 0.7933\n",
      "Epoch 209/300\n",
      "150/150 [==============================] - 0s 225us/sample - loss: 0.5173 - accuracy: 0.7933\n",
      "Epoch 210/300\n",
      "150/150 [==============================] - 0s 173us/sample - loss: 0.5159 - accuracy: 0.8000\n",
      "Epoch 211/300\n",
      "150/150 [==============================] - 0s 219us/sample - loss: 0.5146 - accuracy: 0.8000\n",
      "Epoch 212/300\n",
      "150/150 [==============================] - 0s 197us/sample - loss: 0.5131 - accuracy: 0.8000\n",
      "Epoch 213/300\n",
      "150/150 [==============================] - 0s 183us/sample - loss: 0.5117 - accuracy: 0.8000\n",
      "Epoch 214/300\n",
      "150/150 [==============================] - 0s 191us/sample - loss: 0.5104 - accuracy: 0.8000\n",
      "Epoch 215/300\n",
      "150/150 [==============================] - 0s 196us/sample - loss: 0.5091 - accuracy: 0.8000\n",
      "Epoch 216/300\n",
      "150/150 [==============================] - 0s 260us/sample - loss: 0.5077 - accuracy: 0.8067\n",
      "Epoch 217/300\n",
      "150/150 [==============================] - 0s 239us/sample - loss: 0.5063 - accuracy: 0.8133\n",
      "Epoch 218/300\n",
      "150/150 [==============================] - 0s 240us/sample - loss: 0.5050 - accuracy: 0.8267\n",
      "Epoch 219/300\n",
      "150/150 [==============================] - 0s 315us/sample - loss: 0.5036 - accuracy: 0.8267\n",
      "Epoch 220/300\n",
      "150/150 [==============================] - 0s 220us/sample - loss: 0.5023 - accuracy: 0.8267\n",
      "Epoch 221/300\n",
      "150/150 [==============================] - 0s 187us/sample - loss: 0.5009 - accuracy: 0.8267\n",
      "Epoch 222/300\n",
      "150/150 [==============================] - 0s 221us/sample - loss: 0.4996 - accuracy: 0.8333\n",
      "Epoch 223/300\n",
      "150/150 [==============================] - 0s 137us/sample - loss: 0.4982 - accuracy: 0.8267\n",
      "Epoch 224/300\n",
      "150/150 [==============================] - 0s 181us/sample - loss: 0.4969 - accuracy: 0.8333\n",
      "Epoch 225/300\n",
      "150/150 [==============================] - 0s 188us/sample - loss: 0.4956 - accuracy: 0.8400\n",
      "Epoch 226/300\n",
      "150/150 [==============================] - 0s 178us/sample - loss: 0.4943 - accuracy: 0.8400\n",
      "Epoch 227/300\n",
      "150/150 [==============================] - 0s 157us/sample - loss: 0.4930 - accuracy: 0.8400\n",
      "Epoch 228/300\n",
      "150/150 [==============================] - 0s 174us/sample - loss: 0.4916 - accuracy: 0.8533\n",
      "Epoch 229/300\n",
      "150/150 [==============================] - 0s 219us/sample - loss: 0.4904 - accuracy: 0.8533\n",
      "Epoch 230/300\n",
      "150/150 [==============================] - 0s 164us/sample - loss: 0.4891 - accuracy: 0.8533\n",
      "Epoch 231/300\n",
      "150/150 [==============================] - 0s 282us/sample - loss: 0.4879 - accuracy: 0.8533\n",
      "Epoch 232/300\n",
      "150/150 [==============================] - 0s 401us/sample - loss: 0.4865 - accuracy: 0.8533\n",
      "Epoch 233/300\n",
      "150/150 [==============================] - 0s 186us/sample - loss: 0.4852 - accuracy: 0.8667\n",
      "Epoch 234/300\n",
      "150/150 [==============================] - 0s 291us/sample - loss: 0.4840 - accuracy: 0.8667\n",
      "Epoch 235/300\n",
      "150/150 [==============================] - 0s 189us/sample - loss: 0.4826 - accuracy: 0.8733\n",
      "Epoch 236/300\n",
      "150/150 [==============================] - 0s 152us/sample - loss: 0.4814 - accuracy: 0.8733\n",
      "Epoch 237/300\n",
      "150/150 [==============================] - 0s 200us/sample - loss: 0.4801 - accuracy: 0.8867\n",
      "Epoch 238/300\n",
      "150/150 [==============================] - 0s 177us/sample - loss: 0.4789 - accuracy: 0.8933\n",
      "Epoch 239/300\n",
      "150/150 [==============================] - 0s 152us/sample - loss: 0.4777 - accuracy: 0.8867\n",
      "Epoch 240/300\n",
      "150/150 [==============================] - 0s 221us/sample - loss: 0.4765 - accuracy: 0.8867\n",
      "Epoch 241/300\n",
      "150/150 [==============================] - 0s 213us/sample - loss: 0.4751 - accuracy: 0.8867\n",
      "Epoch 242/300\n",
      "150/150 [==============================] - 0s 304us/sample - loss: 0.4739 - accuracy: 0.8867\n",
      "Epoch 243/300\n",
      "150/150 [==============================] - 0s 458us/sample - loss: 0.4726 - accuracy: 0.8867\n",
      "Epoch 244/300\n",
      "150/150 [==============================] - 0s 683us/sample - loss: 0.4714 - accuracy: 0.8867\n",
      "Epoch 245/300\n",
      "150/150 [==============================] - 0s 350us/sample - loss: 0.4703 - accuracy: 0.8933\n",
      "Epoch 246/300\n",
      "150/150 [==============================] - 0s 243us/sample - loss: 0.4689 - accuracy: 0.8933\n",
      "Epoch 247/300\n",
      "150/150 [==============================] - 0s 197us/sample - loss: 0.4677 - accuracy: 0.8933\n",
      "Epoch 248/300\n",
      "150/150 [==============================] - 0s 169us/sample - loss: 0.4665 - accuracy: 0.9000\n",
      "Epoch 249/300\n",
      "150/150 [==============================] - 0s 232us/sample - loss: 0.4652 - accuracy: 0.9000\n",
      "Epoch 250/300\n",
      "150/150 [==============================] - 0s 207us/sample - loss: 0.4641 - accuracy: 0.9000\n",
      "Epoch 251/300\n",
      "150/150 [==============================] - 0s 295us/sample - loss: 0.4627 - accuracy: 0.9000\n",
      "Epoch 252/300\n",
      "150/150 [==============================] - 0s 209us/sample - loss: 0.4618 - accuracy: 0.9067\n",
      "Epoch 253/300\n",
      "150/150 [==============================] - 0s 223us/sample - loss: 0.4603 - accuracy: 0.9067\n",
      "Epoch 254/300\n",
      "150/150 [==============================] - 0s 211us/sample - loss: 0.4591 - accuracy: 0.9067\n",
      "Epoch 255/300\n",
      "150/150 [==============================] - 0s 336us/sample - loss: 0.4579 - accuracy: 0.9000\n",
      "Epoch 256/300\n",
      "150/150 [==============================] - 0s 208us/sample - loss: 0.4566 - accuracy: 0.9067\n",
      "Epoch 257/300\n",
      "150/150 [==============================] - 0s 233us/sample - loss: 0.4555 - accuracy: 0.9133\n",
      "Epoch 258/300\n",
      "150/150 [==============================] - 0s 192us/sample - loss: 0.4542 - accuracy: 0.9133\n",
      "Epoch 259/300\n",
      "150/150 [==============================] - 0s 243us/sample - loss: 0.4530 - accuracy: 0.9133\n",
      "Epoch 260/300\n",
      "150/150 [==============================] - 0s 430us/sample - loss: 0.4518 - accuracy: 0.9133\n",
      "Epoch 261/300\n",
      "150/150 [==============================] - 0s 289us/sample - loss: 0.4506 - accuracy: 0.9200\n",
      "Epoch 262/300\n",
      "150/150 [==============================] - 0s 218us/sample - loss: 0.4495 - accuracy: 0.9200\n",
      "Epoch 263/300\n",
      "150/150 [==============================] - 0s 270us/sample - loss: 0.4482 - accuracy: 0.9133\n",
      "Epoch 264/300\n",
      "150/150 [==============================] - 0s 139us/sample - loss: 0.4471 - accuracy: 0.9200\n",
      "Epoch 265/300\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 0.4458 - accuracy: 0.9267\n",
      "Epoch 266/300\n",
      "150/150 [==============================] - 0s 209us/sample - loss: 0.4445 - accuracy: 0.9267\n",
      "Epoch 267/300\n",
      "150/150 [==============================] - 0s 255us/sample - loss: 0.4433 - accuracy: 0.9333\n",
      "Epoch 268/300\n",
      "150/150 [==============================] - 0s 373us/sample - loss: 0.4422 - accuracy: 0.9333\n",
      "Epoch 269/300\n",
      "150/150 [==============================] - 0s 280us/sample - loss: 0.4409 - accuracy: 0.9333\n",
      "Epoch 270/300\n",
      "150/150 [==============================] - 0s 219us/sample - loss: 0.4396 - accuracy: 0.9333\n",
      "Epoch 271/300\n",
      "150/150 [==============================] - 0s 248us/sample - loss: 0.4383 - accuracy: 0.9400\n",
      "Epoch 272/300\n",
      "150/150 [==============================] - 0s 316us/sample - loss: 0.4371 - accuracy: 0.9400\n",
      "Epoch 273/300\n",
      "150/150 [==============================] - 0s 328us/sample - loss: 0.4358 - accuracy: 0.9400\n",
      "Epoch 274/300\n",
      "150/150 [==============================] - 0s 228us/sample - loss: 0.4344 - accuracy: 0.9400\n",
      "Epoch 275/300\n",
      "150/150 [==============================] - 0s 173us/sample - loss: 0.4333 - accuracy: 0.9400\n",
      "Epoch 276/300\n",
      "150/150 [==============================] - 0s 378us/sample - loss: 0.4319 - accuracy: 0.9400\n",
      "Epoch 277/300\n",
      "150/150 [==============================] - 0s 163us/sample - loss: 0.4307 - accuracy: 0.9400\n",
      "Epoch 278/300\n",
      "150/150 [==============================] - 0s 175us/sample - loss: 0.4294 - accuracy: 0.9400\n",
      "Epoch 279/300\n",
      "150/150 [==============================] - 0s 360us/sample - loss: 0.4282 - accuracy: 0.9400\n",
      "Epoch 280/300\n",
      "150/150 [==============================] - 0s 205us/sample - loss: 0.4269 - accuracy: 0.9400\n",
      "Epoch 281/300\n",
      "150/150 [==============================] - 0s 401us/sample - loss: 0.4257 - accuracy: 0.9400\n",
      "Epoch 282/300\n",
      "150/150 [==============================] - 0s 238us/sample - loss: 0.4244 - accuracy: 0.9400\n",
      "Epoch 283/300\n",
      "150/150 [==============================] - 0s 233us/sample - loss: 0.4232 - accuracy: 0.9400\n",
      "Epoch 284/300\n",
      "150/150 [==============================] - 0s 285us/sample - loss: 0.4219 - accuracy: 0.9400\n",
      "Epoch 285/300\n",
      "150/150 [==============================] - 0s 210us/sample - loss: 0.4207 - accuracy: 0.9400\n",
      "Epoch 286/300\n",
      "150/150 [==============================] - 0s 187us/sample - loss: 0.4194 - accuracy: 0.9400\n",
      "Epoch 287/300\n",
      "150/150 [==============================] - 0s 224us/sample - loss: 0.4182 - accuracy: 0.9400\n",
      "Epoch 288/300\n",
      "150/150 [==============================] - 0s 191us/sample - loss: 0.4169 - accuracy: 0.9400\n",
      "Epoch 289/300\n",
      "150/150 [==============================] - 0s 269us/sample - loss: 0.4156 - accuracy: 0.9400\n",
      "Epoch 290/300\n",
      "150/150 [==============================] - 0s 216us/sample - loss: 0.4147 - accuracy: 0.9467\n",
      "Epoch 291/300\n",
      "150/150 [==============================] - 0s 201us/sample - loss: 0.4133 - accuracy: 0.9467\n",
      "Epoch 292/300\n",
      "150/150 [==============================] - 0s 240us/sample - loss: 0.4119 - accuracy: 0.9400\n",
      "Epoch 293/300\n",
      "150/150 [==============================] - 0s 228us/sample - loss: 0.4107 - accuracy: 0.9400\n",
      "Epoch 294/300\n",
      "150/150 [==============================] - 0s 341us/sample - loss: 0.4095 - accuracy: 0.9400\n",
      "Epoch 295/300\n",
      "150/150 [==============================] - 0s 290us/sample - loss: 0.4082 - accuracy: 0.9400\n",
      "Epoch 296/300\n",
      "150/150 [==============================] - 0s 163us/sample - loss: 0.4070 - accuracy: 0.9400\n",
      "Epoch 297/300\n",
      "150/150 [==============================] - 0s 239us/sample - loss: 0.4058 - accuracy: 0.9400\n",
      "Epoch 298/300\n",
      "150/150 [==============================] - 0s 176us/sample - loss: 0.4045 - accuracy: 0.9400\n",
      "Epoch 299/300\n",
      "150/150 [==============================] - 0s 238us/sample - loss: 0.4033 - accuracy: 0.9400\n",
      "Epoch 300/300\n",
      "150/150 [==============================] - 0s 291us/sample - loss: 0.4020 - accuracy: 0.9400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4fc81a8e90>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X,y=y,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_iris_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib #look up api...interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('final_iris_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_scaler = joblib.load('iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iris.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {'sepal_length':5.1,\n",
    "                 'sepal_width':3.5,\n",
    "                 'petal_length':1.4,\n",
    "                 'petal_width':0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model,scaler,sample_json):\n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    classes= np.array(['setosa','versicolor','virginica'])\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)[0]\n",
    "    \n",
    "    return classes[class_ind]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model,flower_scaler,flower_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### programatically accessing api ....see and run iris_flask_api.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\n",
    "    'sepal_length':5.1,\n",
    "    'sepal_width':3.5,\n",
    "    'petal_length':1.4,\n",
    "    'petal_width':0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = requests.post('http://localhost:5000/api/flower', json=flower_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"setosa\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
